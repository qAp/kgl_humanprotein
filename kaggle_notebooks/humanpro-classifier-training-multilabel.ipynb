{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015389,
     "end_time": "2021-04-19T18:06:07.686676",
     "exception": false,
     "start_time": "2021-04-19T18:06:07.671287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-04-19T18:06:07.734447Z",
     "iopub.status.busy": "2021-04-19T18:06:07.733783Z",
     "iopub.status.idle": "2021-04-19T18:08:40.746953Z",
     "shell.execute_reply": "2021-04-19T18:08:40.746310Z"
    },
    "papermill": {
     "duration": 153.045874,
     "end_time": "2021-04-19T18:08:40.747195",
     "exception": false,
     "start_time": "2021-04-19T18:06:07.701321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/mmdetection-v280/src/mmpycocotools-12.0.3/mmpycocotools-12.0.3\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from mmpycocotools==12.0.3) (49.6.0.post20201009)\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from mmpycocotools==12.0.3) (0.29.21)\r\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from mmpycocotools==12.0.3) (3.3.3)\r\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (1.19.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (2.4.7)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (0.10.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->mmpycocotools==12.0.3) (7.2.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->mmpycocotools==12.0.3) (1.15.0)\r\n",
      "Building wheels for collected packages: mmpycocotools\r\n",
      "  Building wheel for mmpycocotools (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mmpycocotools: filename=mmpycocotools-12.0.3-cp37-cp37m-linux_x86_64.whl size=272913 sha256=943a126d36dc3959955bb4098233948690f5e6bb12594406b6ba72646e0b2886\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/e0/da/3288fdf3965b5c9090f368462db9d28be2c82013f51821090a\r\n",
      "Successfully built mmpycocotools\r\n",
      "Installing collected packages: mmpycocotools\r\n",
      "Successfully installed mmpycocotools-12.0.3\r\n",
      "Processing /kaggle/input/hpapytorchzoo/pytorch_zoo-master\r\n",
      "Building wheels for collected packages: pytorch-zoo\r\n",
      "  Building wheel for pytorch-zoo (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pytorch-zoo: filename=pytorch_zoo-0.0.0-py3-none-any.whl size=30139 sha256=c7e686d9821dd08b4dea1550c3cfdb89ae9136caaa2fe7f8a4dff1a55adc3807\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/18/21/aff5a8914e22461b2b025a9629c2b70464c36183caaf12bc09\r\n",
      "Successfully built pytorch-zoo\r\n",
      "Installing collected packages: pytorch-zoo\r\n",
      "Successfully installed pytorch-zoo-0.0.0\r\n",
      "Processing /kaggle/input/hpacellsegmentation/HPA-Cell-Segmentation\r\n",
      "Building wheels for collected packages: hpacellseg\r\n",
      "  Building wheel for hpacellseg (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for hpacellseg: filename=hpacellseg-0.1.8-py3-none-any.whl size=14815 sha256=bd75fcca45e9e0db8da4a576a66dca7f1432b0f23676d28238794a421c8c439f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/41/15/9f15b23726cf96bdbc26670ce1c7526c719d4bce49418c1a20\r\n",
      "Successfully built hpacellseg\r\n",
      "Installing collected packages: hpacellseg\r\n",
      "Successfully installed hpacellseg-0.1.8\r\n",
      "Processing /kaggle/input/iterative-stratification/iterative-stratification-master\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.19.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.5.4)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (0.24.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (1.0.0)\r\n",
      "Building wheels for collected packages: iterative-stratification\r\n",
      "  Building wheel for iterative-stratification (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for iterative-stratification: filename=iterative_stratification-0.1.6-py3-none-any.whl size=8401 sha256=2b558e2b24670045e3470257513dacc07bda568eec5c84436e2bb0f70d29fa60\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/47/3f/eb4af42d124f37d23d6f13a4c8bbc32c1d70140e6e1cecb4aa\r\n",
      "Successfully built iterative-stratification\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "Successfully installed iterative-stratification-0.1.6\r\n"
     ]
    }
   ],
   "source": [
    "! rsync -a /kaggle/input/mmdetection-v280/mmdetection /\n",
    "! pip install /kaggle/input/mmdetection-v280/src/mmpycocotools-12.0.3/mmpycocotools-12.0.3/\n",
    "! pip install /kaggle/input/hpapytorchzoo/pytorch_zoo-master/\n",
    "! pip install /kaggle/input/hpacellsegmentation/HPA-Cell-Segmentation/\n",
    "! pip install /kaggle/input/iterative-stratification/iterative-stratification-master/\n",
    "\n",
    "! cp -r /kaggle/input/kgl-humanprotein-data/kgl_humanprotein_data /\n",
    "! cp -r /kaggle/input/humanpro/kgl_humanprotein /\n",
    "\n",
    "import sys\n",
    "sys.path.append('/kgl_humanprotein/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:08:40.806243Z",
     "iopub.status.busy": "2021-04-19T18:08:40.805621Z",
     "iopub.status.idle": "2021-04-19T18:08:45.553698Z",
     "shell.execute_reply": "2021-04-19T18:08:45.552568Z"
    },
    "papermill": {
     "duration": 4.781661,
     "end_time": "2021-04-19T18:08:45.553844",
     "exception": false,
     "start_time": "2021-04-19T18:08:40.772183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on 88d3eac0af0b\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "import functools\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import DataParallel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kgl_humanprotein.utils.common_util import *\n",
    "from kgl_humanprotein.config.config import *\n",
    "from kgl_humanprotein.data_process import *\n",
    "from kgl_humanprotein.datasets.tool import image_to_tensor\n",
    "from kgl_humanprotein.networks.imageclsnet import init_network\n",
    "from kgl_humanprotein.layers.loss import *\n",
    "from kgl_humanprotein.layers.scheduler import *\n",
    "from kgl_humanprotein.utils.augment_util import train_multi_augment2\n",
    "from kgl_humanprotein.utils.log_util import Logger\n",
    "from kgl_humanprotein.run.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:08:45.611136Z",
     "iopub.status.busy": "2021-04-19T18:08:45.609214Z",
     "iopub.status.idle": "2021-04-19T18:08:45.614203Z",
     "shell.execute_reply": "2021-04-19T18:08:45.613148Z"
    },
    "papermill": {
     "duration": 0.036392,
     "end_time": "2021-04-19T18:08:45.614532",
     "exception": false,
     "start_time": "2021-04-19T18:08:45.578140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025439,
     "end_time": "2021-04-19T18:08:45.665953",
     "exception": false,
     "start_time": "2021-04-19T18:08:45.640514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Combine subsets' meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:08:45.723660Z",
     "iopub.status.busy": "2021-04-19T18:08:45.722941Z",
     "iopub.status.idle": "2021-04-19T18:08:45.727161Z",
     "shell.execute_reply": "2021-04-19T18:08:45.726626Z"
    },
    "papermill": {
     "duration": 0.034671,
     "end_time": "2021-04-19T18:08:45.727353",
     "exception": false,
     "start_time": "2021-04-19T18:08:45.692682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_data = Path('/kaggle/input')\n",
    "dir_mdata = Path('/kaggle/mdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:08:45.783370Z",
     "iopub.status.busy": "2021-04-19T18:08:45.782233Z",
     "iopub.status.idle": "2021-04-19T18:08:49.806861Z",
     "shell.execute_reply": "2021-04-19T18:08:49.806349Z"
    },
    "papermill": {
     "duration": 4.054318,
     "end_time": "2021-04-19T18:08:49.807026",
     "exception": false,
     "start_time": "2021-04-19T18:08:45.752708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 826 ms, sys: 468 ms, total: 1.29 s\n",
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_cells = combine_subsets_metadata(dir_data, n_subsets)\n",
    "df_cells = pd.read_feather('/kaggle/input/humanpro-data-multilabel-cells-meta/train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:08:49.864777Z",
     "iopub.status.busy": "2021-04-19T18:08:49.863796Z",
     "iopub.status.idle": "2021-04-19T18:08:51.703990Z",
     "shell.execute_reply": "2021-04-19T18:08:51.703458Z"
    },
    "papermill": {
     "duration": 1.871073,
     "end_time": "2021-04-19T18:08:51.704200",
     "exception": false,
     "start_time": "2021-04-19T18:08:49.833127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_mdata_raw = dir_mdata/'raw'\n",
    "dir_mdata_raw.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "df_cells.to_feather(dir_mdata_raw/'train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:08:51.935330Z",
     "iopub.status.busy": "2021-04-19T18:08:51.934346Z",
     "iopub.status.idle": "2021-04-19T18:08:51.937778Z",
     "shell.execute_reply": "2021-04-19T18:08:51.937265Z"
    },
    "papermill": {
     "duration": 0.203269,
     "end_time": "2021-04-19T18:08:51.937914",
     "exception": false,
     "start_time": "2021-04-19T18:08:51.734645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del df_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025573,
     "end_time": "2021-04-19T18:08:51.989690",
     "exception": false,
     "start_time": "2021-04-19T18:08:51.964117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Filter samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:08:52.060151Z",
     "iopub.status.busy": "2021-04-19T18:08:52.059117Z",
     "iopub.status.idle": "2021-04-19T18:08:53.446776Z",
     "shell.execute_reply": "2021-04-19T18:08:53.447424Z"
    },
    "papermill": {
     "duration": 1.432776,
     "end_time": "2021-04-19T18:08:53.447671",
     "exception": false,
     "start_time": "2021-04-19T18:08:52.014895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove samples whose target is ''\n",
    "df_cells = pd.read_feather(dir_mdata_raw/'train.feather')\n",
    "df_cells = df_cells[df_cells['Target'] != ''].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:08:53.509267Z",
     "iopub.status.busy": "2021-04-19T18:08:53.508619Z",
     "iopub.status.idle": "2021-04-19T18:08:53.513886Z",
     "shell.execute_reply": "2021-04-19T18:08:53.514322Z"
    },
    "papermill": {
     "duration": 0.039772,
     "end_time": "2021-04-19T18:08:53.514481",
     "exception": false,
     "start_time": "2021-04-19T18:08:53.474709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153899, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cells.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:08:53.575675Z",
     "iopub.status.busy": "2021-04-19T18:08:53.574829Z",
     "iopub.status.idle": "2021-04-19T18:08:53.577856Z",
     "shell.execute_reply": "2021-04-19T18:08:53.577391Z"
    },
    "papermill": {
     "duration": 0.036578,
     "end_time": "2021-04-19T18:08:53.577983",
     "exception": false,
     "start_time": "2021-04-19T18:08:53.541405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Limit number of samples per label\n",
    "\n",
    "def cap_number_per_label(df_cells, cap=10_000, idx_start=0):\n",
    "    df_cells_cap = pd.DataFrame()\n",
    "    for label in df_cells.Target.unique():\n",
    "        df = df_cells[df_cells.Target==label]\n",
    "        if len(df) > cap:\n",
    "            df = df.iloc[idx_start:idx_start + cap]\n",
    "        df_cells_cap = df_cells_cap.append(df, ignore_index=True)\n",
    "    return df_cells_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:08:53.648178Z",
     "iopub.status.busy": "2021-04-19T18:08:53.647332Z",
     "iopub.status.idle": "2021-04-19T18:09:03.495988Z",
     "shell.execute_reply": "2021-04-19T18:09:03.495463Z"
    },
    "papermill": {
     "duration": 9.891073,
     "end_time": "2021-04-19T18:09:03.496276",
     "exception": false,
     "start_time": "2021-04-19T18:08:53.605203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cells = cap_number_per_label(df_cells, cap=5_000, idx_start=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:09:03.587634Z",
     "iopub.status.busy": "2021-04-19T18:09:03.586355Z",
     "iopub.status.idle": "2021-04-19T18:09:03.594916Z",
     "shell.execute_reply": "2021-04-19T18:09:03.595632Z"
    },
    "papermill": {
     "duration": 0.065361,
     "end_time": "2021-04-19T18:09:03.595803",
     "exception": false,
     "start_time": "2021-04-19T18:09:03.530442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16         5000\n",
       "13         5000\n",
       "5          5000\n",
       "0          5000\n",
       "14         5000\n",
       "           ... \n",
       "9|17          1\n",
       "9|13|16       1\n",
       "0|2|13        1\n",
       "0|1|2         1\n",
       "0|5|12        1\n",
       "Name: Target, Length: 149, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cells.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:09:03.921875Z",
     "iopub.status.busy": "2021-04-19T18:09:03.919039Z",
     "iopub.status.idle": "2021-04-19T18:09:05.140462Z",
     "shell.execute_reply": "2021-04-19T18:09:05.139296Z"
    },
    "papermill": {
     "duration": 1.513232,
     "end_time": "2021-04-19T18:09:05.140622",
     "exception": false,
     "start_time": "2021-04-19T18:09:03.627390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cells.to_feather(dir_mdata_raw/'train.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029036,
     "end_time": "2021-04-19T18:09:05.199246",
     "exception": false,
     "start_time": "2021-04-19T18:09:05.170210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:09:05.263272Z",
     "iopub.status.busy": "2021-04-19T18:09:05.262295Z",
     "iopub.status.idle": "2021-04-19T18:09:28.248027Z",
     "shell.execute_reply": "2021-04-19T18:09:28.248534Z"
    },
    "papermill": {
     "duration": 23.020097,
     "end_time": "2021-04-19T18:09:28.248702",
     "exception": false,
     "start_time": "2021-04-19T18:09:05.228605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.7 s, sys: 364 ms, total: 23 s\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate_meta(dir_mdata, 'train.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028548,
     "end_time": "2021-04-19T18:09:28.306138",
     "exception": false,
     "start_time": "2021-04-19T18:09:28.277590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:09:28.378935Z",
     "iopub.status.busy": "2021-04-19T18:09:28.377946Z",
     "iopub.status.idle": "2021-04-19T18:09:35.410171Z",
     "shell.execute_reply": "2021-04-19T18:09:35.409148Z"
    },
    "papermill": {
     "duration": 7.075065,
     "end_time": "2021-04-19T18:09:35.410308",
     "exception": false,
     "start_time": "2021-04-19T18:09:28.335243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nucleoplasm 7922 1981\n",
      "Nuclear membrane 4720 1180\n",
      "Nucleoli 5069 1267\n",
      "Nucleoli fibrillar center 3050 762\n",
      "Nuclear speckles 4136 1034\n",
      "Nuclear bodies 5091 1272\n",
      "Endoplasmic reticulum 1601 400\n",
      "Golgi apparatus 4715 1178\n",
      "Intermediate filaments 2322 580\n",
      "Actin filaments 3698 924\n",
      "Microtubules 4177 1044\n",
      "Mitotic spindle 0 0\n",
      "Centrosome 3283 821\n",
      "Plasma membrane 5771 1443\n",
      "Mitochondria 4513 1128\n",
      "Aggresome 488 121\n",
      "Cytosol 6082 1521\n",
      "Vesicles and punctate cytosolic patterns 805 202\n",
      "Negative 0 0\n",
      "create split file: /kaggle/mdata/split/random_folds5/random_train_cv0.feather, shape: (60311, 29)\n",
      "create split file: /kaggle/mdata/split/random_folds5/random_valid_cv0.feather, shape: (15082, 29)\n",
      "create split file: /kaggle/mdata/split/random_folds5/random_train_cv1.feather, shape: (60334, 29)\n",
      "create split file: /kaggle/mdata/split/random_folds5/random_valid_cv1.feather, shape: (15059, 29)\n",
      "create split file: /kaggle/mdata/split/random_folds5/random_train_cv2.feather, shape: (60368, 29)\n",
      "create split file: /kaggle/mdata/split/random_folds5/random_valid_cv2.feather, shape: (15025, 29)\n",
      "create split file: /kaggle/mdata/split/random_folds5/random_train_cv3.feather, shape: (60263, 29)\n",
      "create split file: /kaggle/mdata/split/random_folds5/random_valid_cv3.feather, shape: (15130, 29)\n",
      "create split file: /kaggle/mdata/split/random_folds5/random_train_cv4.feather, shape: (60296, 29)\n",
      "create split file: /kaggle/mdata/split/random_folds5/random_valid_cv4.feather, shape: (15097, 29)\n",
      "CPU times: user 6.21 s, sys: 803 ms, total: 7.01 s\n",
      "Wall time: 7.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_meta = pd.read_feather(dir_mdata/'meta'/'train_meta.feather')\n",
    "create_random_split(dir_mdata, train_meta, n_splits=5, alias='random')\n",
    "del train_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029681,
     "end_time": "2021-04-19T18:09:35.472968",
     "exception": false,
     "start_time": "2021-04-19T18:09:35.443287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:09:35.580825Z",
     "iopub.status.busy": "2021-04-19T18:09:35.558825Z",
     "iopub.status.idle": "2021-04-19T18:09:35.583507Z",
     "shell.execute_reply": "2021-04-19T18:09:35.583012Z"
    },
    "papermill": {
     "duration": 0.080825,
     "end_time": "2021-04-19T18:09:35.583655",
     "exception": false,
     "start_time": "2021-04-19T18:09:35.502830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kgl_humanprotein.datasets.protein_dataset import ProteinDataset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "def main_training(dir_data, dir_mdata, dir_results, out_dir, gpu_id='0', \n",
    "                  arch='class_densenet121_dropout', pretrained=None, model_multicell=None, \n",
    "                  num_classes=19, in_channels=4, loss='FocalSymmetricLovaszHardLogLoss',\n",
    "                  scheduler='Adam45', epochs=55, img_size=768, crop_size=512, batch_size=32, \n",
    "                  workers=3, pin_memory=True, split_name='random_ext_folds5', fold=0, \n",
    "                  clipnorm=1, resume=None):\n",
    "    '''\n",
    "    PyTorch Protein Classification.  Main training function.\n",
    "    \n",
    "    Args:\n",
    "        dir_data (str, Path): Directory where training subsets are.\n",
    "        dir_mdata (str, Path): Directory where training meta data is.\n",
    "        dir_results (std, Path): Directory to save training results.\n",
    "        out_dir (str): \n",
    "            Name/label for this training run.  Will be used to create\n",
    "            directory under `dir_results`.\n",
    "        gpu_id (str): GPU id used for training. Default: '0'\n",
    "        arch (str): Model architecture.  \n",
    "            Default: ``'class_densenet121_dropout'``\n",
    "        pretrained (Path, str): Path to a pretrained model.  These are\n",
    "            the parameters just before training starts.\n",
    "        model_multicell (Path, str): Path to multi-cell model \n",
    "            to start training from. Default: None\n",
    "        num_classes (int): Number of classes. Default: 19 \n",
    "        in_channels (int): In channels. Default: 4\n",
    "        loss (str, optional): Loss function. \n",
    "            One of ``'FocalSymmetricLovaszHardLogLoss'``. \n",
    "            Default: ``'FocalSymmetricLovaszHardLogLoss'``\n",
    "        scheduler (str): Scheduler name. Default: ``'Adam45'``\n",
    "        epochs (int): Number of total epochs to run. Default: 55\n",
    "        img_size (int): Image size.  Default: 768\n",
    "        crop_size (int): Crop size.  Default: 512\n",
    "        batch_size (int): Train mini-batch size. Default: 32\n",
    "        workers (int): Number of data loading workers. Default: 3\n",
    "        pin_memory (bool): DataLoader's ``pin_memory`` argument.\n",
    "        split_name (str, optional): Split name.  \n",
    "            One of: ``'random_ext_folds5'``, \n",
    "            or ``'random_ext_noleak_clean_folds5'``. \n",
    "            Default: ``'random_ext_folds5'``\n",
    "        fold (int): Index of fold. Default: 0\n",
    "        clipnorm (int): Clip grad norm'. Default: 1\n",
    "        resume (str): Name of the latest checkpoint. Default: None\n",
    "    '''\n",
    "    log_out_dir = opj(dir_results, 'logs', out_dir, 'fold%d' % fold)\n",
    "    if not ope(log_out_dir):\n",
    "        os.makedirs(log_out_dir)\n",
    "    log = Logger()\n",
    "    log.open(opj(log_out_dir, 'log.train.txt'), mode='a')\n",
    "\n",
    "    model_out_dir = opj(dir_results, 'models', out_dir, 'fold%d' % fold)\n",
    "    log.write(\">> Creating directory if it does not exist:\\n>> '{}'\\n\".format(model_out_dir))\n",
    "    if not ope(model_out_dir):\n",
    "        os.makedirs(model_out_dir)\n",
    "\n",
    "    # set cuda visible device\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # set random seeds\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    model_params = {}\n",
    "    model_params['architecture'] = arch\n",
    "    model_params['num_classes'] = num_classes\n",
    "    model_params['in_channels'] = in_channels\n",
    "    model = init_network(model_params, model_multicell=model_multicell)\n",
    "    \n",
    "    if pretrained:\n",
    "        print(f'Loading pretrained model {pretrained}')\n",
    "        checkpoint = torch.load(pretrained)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    # move network to gpu\n",
    "    model = DataParallel(model)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # define loss function (criterion)\n",
    "    try:\n",
    "        criterion = eval(loss)().to(DEVICE)\n",
    "    except:\n",
    "        raise(RuntimeError(\"Loss {} not available!\".format(loss)))\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_loss = 1e5\n",
    "    best_epoch = 0\n",
    "    best_focal = 1e5\n",
    "\n",
    "    # define scheduler\n",
    "    try:\n",
    "        scheduler = eval(scheduler)()\n",
    "    except:\n",
    "        raise (RuntimeError(\"Scheduler {} not available!\".format(scheduler)))\n",
    "    optimizer = scheduler.schedule(model, start_epoch, epochs)[0]\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if resume:\n",
    "        resume = os.path.join(model_out_dir, resume)\n",
    "        if os.path.isfile(resume):\n",
    "            # load checkpoint weights and update model and optimizer\n",
    "            log.write(\">> Loading checkpoint:\\n>> '{}'\\n\".format(resume))\n",
    "\n",
    "            checkpoint = torch.load(resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_epoch = checkpoint['best_epoch']\n",
    "            best_focal = checkpoint['best_score']\n",
    "            model.module.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "            optimizer_fpath = resume.replace('.pth', '_optim.pth')\n",
    "            if ope(optimizer_fpath):\n",
    "                log.write(\">> Loading checkpoint:\\n>> '{}'\\n\".format(optimizer_fpath))\n",
    "                optimizer.load_state_dict(torch.load(optimizer_fpath)['optimizer'])\n",
    "            log.write(\">>>> loaded checkpoint:\\n>>>> '{}' (epoch {})\\n\".format(resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            log.write(\">> No checkpoint found at '{}'\\n\".format(resume))\n",
    "\n",
    "    # Data loading code\n",
    "    train_transform = train_multi_augment2\n",
    "    train_split_file = dir_mdata / 'split'/ split_name / f'random_train_cv{fold}.feather'\n",
    "    train_dataset = ProteinDataset(\n",
    "        dir_data,\n",
    "        train_split_file,\n",
    "        img_size=img_size,\n",
    "        is_trainset=True,\n",
    "        return_label=True,\n",
    "        in_channels=in_channels,\n",
    "        transform=train_transform,\n",
    "        crop_size=crop_size,\n",
    "        random_crop=True)\n",
    "    \n",
    "    label_weights = get_label_weights(train_dataset.split_df)\n",
    "    weights = torch.from_numpy(train_dataset.split_df['Target']\n",
    "                               .apply(lambda o: label_weights[o]).values)\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=sampler,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "        num_workers=workers,\n",
    "        pin_memory=pin_memory)\n",
    "    \n",
    "    valid_split_file = (dir_mdata/'split'/split_name/\n",
    "                        f'random_valid_cv{fold}.feather')\n",
    "    \n",
    "    valid_dataset = ProteinDataset(\n",
    "        dir_data,\n",
    "        valid_split_file,\n",
    "        img_size=img_size,\n",
    "        is_trainset=True,\n",
    "        return_label=True,\n",
    "        in_channels=in_channels,\n",
    "        transform=None,\n",
    "        crop_size=crop_size,\n",
    "        random_crop=False)\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        sampler=SequentialSampler(valid_dataset),\n",
    "        batch_size=batch_size,\n",
    "        drop_last=False,\n",
    "        num_workers=workers,\n",
    "        pin_memory=pin_memory)\n",
    "\n",
    "    focal_loss = FocalLoss().to(DEVICE)\n",
    "    log.write('** start training here! **\\n')\n",
    "    log.write('\\n')\n",
    "    log.write('epoch    iter      rate     |  train_loss/acc  |    valid_loss/acc/focal/kaggle     |best_epoch/best_focal|  min \\n')\n",
    "    log.write('-----------------------------------------------------------------------------------------------------------------\\n')\n",
    "    start_epoch += 1\n",
    "    for epoch in range(start_epoch, epochs + 1):\n",
    "        end = time.time()\n",
    "\n",
    "        # set manual seeds per epoch\n",
    "        np.random.seed(epoch)\n",
    "        torch.manual_seed(epoch)\n",
    "        torch.cuda.manual_seed_all(epoch)\n",
    "\n",
    "        # adjust learning rate for each epoch\n",
    "        lr_list = scheduler.step(model, epoch, epochs)\n",
    "        lr = lr_list[0]\n",
    "\n",
    "        # train for one epoch on train set\n",
    "        iter, train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch, clipnorm=clipnorm, lr=lr)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valid_loss, valid_acc, valid_focal_loss, kaggle_score = validate(valid_loader, model, criterion, epoch, focal_loss)\n",
    "\n",
    "        # remember best loss and save checkpoint\n",
    "        is_best = valid_focal_loss < best_focal\n",
    "        best_loss = min(valid_focal_loss, best_loss)\n",
    "        best_epoch = epoch if is_best else best_epoch\n",
    "        best_focal = valid_focal_loss if is_best else best_focal\n",
    "\n",
    "        print('\\r', end='', flush=True)\n",
    "        log.write('%5.1f   %5d    %0.6f   |  %0.4f  %0.4f  |    %0.4f  %6.4f %6.4f %6.4f    |  %6.1f    %6.4f   | %3.1f min \\n' % \\\n",
    "                  (epoch, iter + 1, lr, train_loss, train_acc, valid_loss, valid_acc, valid_focal_loss, kaggle_score,\n",
    "                   best_epoch, best_focal, (time.time() - end) / 60))\n",
    "\n",
    "        save_model(model, is_best, model_out_dir, optimizer=optimizer, epoch=epoch, best_epoch=best_epoch, best_focal=best_focal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:09:35.652732Z",
     "iopub.status.busy": "2021-04-19T18:09:35.651908Z",
     "iopub.status.idle": "2021-04-19T18:09:35.655467Z",
     "shell.execute_reply": "2021-04-19T18:09:35.655863Z"
    },
    "papermill": {
     "duration": 0.04128,
     "end_time": "2021-04-19T18:09:35.656028",
     "exception": false,
     "start_time": "2021-04-19T18:09:35.614748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_multicell = (\n",
    "    '../../kgl_humanprotein_data/result/models/'\n",
    "    'external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds/'\n",
    "    'fold0/final.pth')\n",
    "pretrained = Path(\n",
    "    '/kaggle/input/humanpro-classifier-crop/results/models/'\n",
    "    'external_crop256_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds/'\n",
    "    'fold0/final.pth')\n",
    "\n",
    "gpu_id = '0' # '0,1,2,3'\n",
    "arch = 'class_densenet121_dropout'\n",
    "num_classes = len(LABEL_NAME_LIST)\n",
    "scheduler = 'Adam55'\n",
    "epochs = 10 #55\n",
    "resume = None \n",
    "sz_img = 384\n",
    "crop_size = 256 #512\n",
    "batch_size = 76\n",
    "split_name = 'random_folds5'\n",
    "fold = 0\n",
    "workers = 3\n",
    "pin_memory = True\n",
    "\n",
    "dir_results = Path('results')\n",
    "dir_results.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "out_dir = Path(f'external_crop{crop_size}_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T18:09:35.724748Z",
     "iopub.status.busy": "2021-04-19T18:09:35.724165Z",
     "iopub.status.idle": "2021-04-19T20:58:37.505136Z",
     "shell.execute_reply": "2021-04-19T20:58:37.504365Z"
    },
    "papermill": {
     "duration": 10141.818533,
     "end_time": "2021-04-19T20:58:37.505326",
     "exception": false,
     "start_time": "2021-04-19T18:09:35.686793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating directory if it does not exist:\n",
      ">> 'results/models/external_crop256_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds/fold0'\n",
      ">> Using pre-trained model.\n",
      ">> Loading multi-cell model.\n",
      "Loading pretrained model /kaggle/input/humanpro-classifier-crop/results/models/external_crop256_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds/fold0/final.pth\n",
      "** start training here! **\n",
      "\n",
      "epoch    iter      rate     |  train_loss/acc  |    valid_loss/acc/focal/kaggle     |best_epoch/best_focal|  min \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "  1.0     793    0.000300   |  0.8967  0.9768  |    0.9166  0.9740 0.6288 0.7102    |     1.0    0.6288   | 21.5 min \n",
      "  2.0     793    0.000300   |  0.4538  0.9833  |    0.8936  0.9745 0.6168 0.7112    |     2.0    0.6168   | 16.7 min \n",
      "  3.0     793    0.000300   |  0.3191  0.9865  |    0.7608  0.9758 0.5260 0.7111    |     3.0    0.5260   | 16.3 min \n",
      "  4.0     793    0.000300   |  0.2591  0.9884  |    0.7642  0.9755 0.5265 0.7147    |     3.0    0.5260   | 16.1 min \n",
      "  5.0     793    0.000300   |  0.2237  0.9895  |    0.7934  0.9766 0.5395 0.7163    |     3.0    0.5260   | 16.2 min \n",
      "  6.0     793    0.000300   |  0.2026  0.9904  |    0.7063  0.9753 0.4749 0.7196    |     6.0    0.4749   | 16.4 min \n",
      "  7.0     793    0.000300   |  0.1815  0.9911  |    0.6983  0.9764 0.4602 0.7232    |     7.0    0.4602   | 16.4 min \n",
      "  8.0     793    0.000300   |  0.1645  0.9916  |    0.7138  0.9761 0.4796 0.7267    |     7.0    0.4602   | 16.6 min \n",
      "  9.0     793    0.000300   |  0.1579  0.9921  |    0.7109  0.9764 0.4792 0.7215    |     7.0    0.4602   | 16.1 min \n",
      " 10.0     793    0.000300   |  0.1439  0.9925  |    0.6981  0.9750 0.4906 0.7234    |     7.0    0.4602   | 16.4 min \n"
     ]
    }
   ],
   "source": [
    "main_training(dir_data, dir_mdata, dir_results, out_dir, \n",
    "              split_name=split_name, fold=fold,\n",
    "              arch=arch, pretrained=pretrained, model_multicell=model_multicell, scheduler=scheduler,\n",
    "              epochs=epochs, resume=resume,\n",
    "              img_size=sz_img, crop_size=crop_size, batch_size=batch_size, \n",
    "              gpu_id=gpu_id, workers=workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T20:58:42.475543Z",
     "iopub.status.busy": "2021-04-19T20:58:42.450259Z",
     "iopub.status.idle": "2021-04-19T20:58:46.172945Z",
     "shell.execute_reply": "2021-04-19T20:58:46.172073Z"
    },
    "papermill": {
     "duration": 6.376078,
     "end_time": "2021-04-19T20:58:46.173237",
     "exception": false,
     "start_time": "2021-04-19T20:58:39.797159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cp -r results/ /kaggle/working/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 8.530096,
     "end_time": "2021-04-19T20:58:57.521771",
     "exception": false,
     "start_time": "2021-04-19T20:58:48.991675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10381.510835,
   "end_time": "2021-04-19T20:59:03.471167",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-19T18:06:01.960332",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
