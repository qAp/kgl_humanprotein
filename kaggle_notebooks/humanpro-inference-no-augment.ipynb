{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-09T13:26:48.643740Z",
     "iopub.status.busy": "2021-05-09T13:26:48.638611Z",
     "iopub.status.idle": "2021-05-09T13:28:39.138303Z",
     "shell.execute_reply": "2021-05-09T13:28:39.137524Z"
    },
    "papermill": {
     "duration": 110.538642,
     "end_time": "2021-05-09T13:28:39.138569",
     "exception": false,
     "start_time": "2021-05-09T13:26:48.599927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... INSTALLING AND IMPORTING CELL-PROFILER TOOL (HPACELLSEG) ...\n",
      "\n",
      "\n",
      "... OTHER IMPORTS STARTING ...\n",
      "\n",
      "\n",
      "\tVERSION INFORMATION\n",
      "\t\t– TENSORFLOW VERSION: 2.4.0\n",
      "\t\t– NUMPY VERSION: 1.19.5\n",
      "\t\t– MATPLOTLIB VERSION: 3.3.3\n",
      "\n",
      "\n",
      "... IMPORTS COMPLETE ...\n",
      "\n",
      "1 ... Physical GPUs, 1 Logical GPUs ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell Segmentator Tool\n",
    "print(\"\\n... INSTALLING AND IMPORTING CELL-PROFILER TOOL (HPACELLSEG) ...\\n\")\n",
    "try:\n",
    "    import hpacellseg.cellsegmentator as cellsegmentator\n",
    "    from hpacellseg.utils import label_cell\n",
    "except:\n",
    "    !pip install -q \"/kaggle/input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"\n",
    "    !pip install -q \"/kaggle/input/hpapytorchzoozip/pytorch_zoo-master\"\n",
    "    !pip install -q \"/kaggle/input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\"\n",
    "    import hpacellseg.cellsegmentator as cellsegmentator\n",
    "    from hpacellseg.utils import label_cell\n",
    "\n",
    "print(\"\\n... OTHER IMPORTS STARTING ...\\n\")\n",
    "print(\"\\n\\tVERSION INFORMATION\")\n",
    "\n",
    "# Machine Learning and Data Science Imports\n",
    "import tensorflow as tf; print(f\"\\t\\t– TENSORFLOW VERSION: {tf.__version__}\");\n",
    "import pandas as pd; pd.options.mode.chained_assignment = None;\n",
    "import numpy as np; print(f\"\\t\\t– NUMPY VERSION: {np.__version__}\");\n",
    "import torch\n",
    "\n",
    "# Built In Imports\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "from glob import glob\n",
    "import warnings\n",
    "import requests\n",
    "import imageio\n",
    "import IPython\n",
    "import urllib\n",
    "import zipfile\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import math\n",
    "import tqdm\n",
    "import time\n",
    "import gzip\n",
    "import sys\n",
    "import ast\n",
    "import csv; csv.field_size_limit(sys.maxsize)\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "\n",
    "# Visualization Imports\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as patches\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib; print(f\"\\t\\t– MATPLOTLIB VERSION: {matplotlib.__version__}\");\n",
    "import plotly\n",
    "import PIL\n",
    "import cv2\n",
    "\n",
    "# Submission Imports\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import base64\n",
    "import zlib\n",
    "\n",
    "# PRESETS\n",
    "LBL_NAMES = [\"Nucleoplasm\", \"Nuclear Membrane\", \"Nucleoli\", \"Nucleoli Fibrillar Center\", \"Nuclear Speckles\", \"Nuclear Bodies\", \"Endoplasmic Reticulum\", \"Golgi Apparatus\", \"Intermediate Filaments\", \"Actin Filaments\", \"Microtubules\", \"Mitotic Spindle\", \"Centrosome\", \"Plasma Membrane\", \"Mitochondria\", \"Aggresome\", \"Cytosol\", \"Vesicles\", \"Negative\"]\n",
    "INT_2_STR = {x:LBL_NAMES[x] for x in np.arange(19)}\n",
    "INT_2_STR_LOWER = {k:v.lower().replace(\" \", \"_\") for k,v in INT_2_STR.items()}\n",
    "STR_2_INT_LOWER = {v:k for k,v in INT_2_STR_LOWER.items()}\n",
    "STR_2_INT = {v:k for k,v in INT_2_STR.items()}\n",
    "FIG_FONT = dict(family=\"Helvetica, Arial\", size=14, color=\"#7f7f7f\")\n",
    "LABEL_COLORS = [px.colors.label_rgb(px.colors.convert_to_RGB_255(x)) for x in sns.color_palette(\"Spectral\", len(LBL_NAMES))]\n",
    "LABEL_COL_MAP = {str(i):x for i,x in enumerate(LABEL_COLORS)}\n",
    "\n",
    "print(\"\\n\\n... IMPORTS COMPLETE ...\\n\")\n",
    "\n",
    "# Stop Tensorflow From Eating All The Memory\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"... Physical GPUs,\", len(logical_gpus), \"Logical GPUs ...\\n\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T13:28:39.182736Z",
     "iopub.status.busy": "2021-05-09T13:28:39.181451Z",
     "iopub.status.idle": "2021-05-09T13:29:04.303280Z",
     "shell.execute_reply": "2021-05-09T13:29:04.304065Z"
    },
    "papermill": {
     "duration": 25.151084,
     "end_time": "2021-05-09T13:29:04.304365",
     "exception": false,
     "start_time": "2021-05-09T13:28:39.153281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on 445f94ff6ecb\n"
     ]
    }
   ],
   "source": [
    "! cp -r /kaggle/input/kgl-humanprotein-data/kgl_humanprotein_data /\n",
    "! cp -r /kaggle/input/humanpro/kgl_humanprotein /\n",
    "\n",
    "sys.path.append('/kgl_humanprotein')\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from kgl_humanprotein.utils.common_util import *\n",
    "from kgl_humanprotein.networks.imageclsnet import init_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T13:29:04.342531Z",
     "iopub.status.busy": "2021-05-09T13:29:04.341788Z",
     "iopub.status.idle": "2021-05-09T13:29:04.781056Z",
     "shell.execute_reply": "2021-05-09T13:29:04.781611Z"
    },
    "papermill": {
     "duration": 0.462857,
     "end_time": "2021-05-09T13:29:04.781851",
     "exception": false,
     "start_time": "2021-05-09T13:29:04.318994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... The number of testing images is 2236\n",
      "\t--> i.e. 559 4-channel images ...\n",
      "\n",
      "\n",
      "SAMPLE SUBMISSION DATAFRAME\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0173029a-161d-40ef-af28-2342915b22fb</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 1 eNoLCAgIsAQABJ4Beg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>020a29cf-2c24-478b-8603-c22a90dc3e31</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 1 eNoLCAjJNgIABNkBkg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 1 eNoLCAjJNgIABNkBkg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ff069fa2-d948-408e-91b3-034cfea428d1</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 1 eNoLCAgIsAQABJ4Beg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>ff23eea9-4bbe-42af-a8da-9ae16321fc6d</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ID  ImageWidth  ImageHeight  \\\n",
       "0    0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
       "4    0173029a-161d-40ef-af28-2342915b22fb        3072         3072   \n",
       "6    020a29cf-2c24-478b-8603-c22a90dc3e31        1728         1728   \n",
       "554  fea47298-266a-4cf4-93bd-55d1bcc2fc7d        1728         1728   \n",
       "557  ff069fa2-d948-408e-91b3-034cfea428d1        3072         3072   \n",
       "558  ff23eea9-4bbe-42af-a8da-9ae16321fc6d        2048         2048   \n",
       "\n",
       "             PredictionString  \n",
       "0    0 1 eNoLCAgIMAEABJkBdQ==  \n",
       "4    0 1 eNoLCAgIsAQABJ4Beg==  \n",
       "6    0 1 eNoLCAjJNgIABNkBkg==  \n",
       "554  0 1 eNoLCAjJNgIABNkBkg==  \n",
       "557  0 1 eNoLCAgIsAQABJ4Beg==  \n",
       "558  0 1 eNoLCAgIMAEABJkBdQ==  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define paths to nucleus and cell models for the cellsegmentator class\n",
    "NUC_MODEL = '/kaggle/input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth'\n",
    "CELL_MODEL = '/kaggle/input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth'\n",
    "\n",
    "B2_CELL_CLSFR_DIR = \"/kaggle/input/hpa-cellwise-classification-training/ebnet_b2_wdensehead/ckpt-0007-0.0901.ckpt\"\n",
    "\n",
    "# Define the path to the competition data directory\n",
    "DATA_DIR = \"/kaggle/input/hpa-single-cell-image-classification\"\n",
    "\n",
    "# Define the paths to the training and testing tfrecord and \n",
    "# image folders respectively for the competition data\n",
    "TEST_IMG_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "# Capture all the relevant full image paths for the competition dataset\n",
    "TEST_IMG_PATHS = sorted([os.path.join(TEST_IMG_DIR, f_name) for f_name in os.listdir(TEST_IMG_DIR)])\n",
    "print(f\"... The number of testing images is {len(TEST_IMG_PATHS)}\" \\\n",
    "      f\"\\n\\t--> i.e. {len(TEST_IMG_PATHS)//4} 4-channel images ...\")\n",
    "\n",
    "# Define paths to the relevant csv files\n",
    "SWAP_SS_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "# Create the relevant dataframe objects\n",
    "ss_df = pd.read_csv(SWAP_SS_CSV)\n",
    "\n",
    "# helps us control whether this is the full submission or just the initial pass\n",
    "IS_DEMO = len(ss_df)==559\n",
    "\n",
    "if IS_DEMO:\n",
    "    ss_df_1 = ss_df.drop_duplicates(\"ImageWidth\", keep=\"first\")\n",
    "    ss_df_2 = ss_df.drop_duplicates(\"ImageWidth\", keep=\"last\")\n",
    "    ss_df = pd.concat([ss_df_1, ss_df_2])\n",
    "    del ss_df_1; del ss_df_2; gc.collect();\n",
    "    print(\"\\n\\nSAMPLE SUBMISSION DATAFRAME\\n\\n\")\n",
    "    display(ss_df)\n",
    "else:\n",
    "    print(\"\\n\\nSAMPLE SUBMISSION DATAFRAME\\n\\n\")\n",
    "    display(ss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-05-09T13:29:04.856595Z",
     "iopub.status.busy": "2021-05-09T13:29:04.827307Z",
     "iopub.status.idle": "2021-05-09T13:29:04.890419Z",
     "shell.execute_reply": "2021-05-09T13:29:04.891062Z"
    },
    "papermill": {
     "duration": 0.091797,
     "end_time": "2021-05-09T13:29:04.891258",
     "exception": false,
     "start_time": "2021-05-09T13:29:04.799461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binary_mask_to_ascii(mask, mask_val=1):\n",
    "    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "    mask = np.where(mask==mask_val, 1, 0).astype(np.bool)\n",
    "    \n",
    "    # check input mask --\n",
    "    if mask.dtype != np.bool:\n",
    "        raise ValueError(f\"encode_binary_mask expects a binary mask, received dtype == {mask.dtype}\")\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(f\"encode_binary_mask expects a 2d mask, received shape == {mask.shape}\")\n",
    "\n",
    "    # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return base64_str.decode()\n",
    "\n",
    "\n",
    "def rle_encoding(img, mask_val=1):\n",
    "    \"\"\"\n",
    "    Turns our masks into RLE encoding to easily store them\n",
    "    and feed them into models later on\n",
    "    https://en.wikipedia.org/wiki/Run-length_encoding\n",
    "    \n",
    "    Args:\n",
    "        img (np.array): Segmentation array\n",
    "        mask_val (int): Which value to use to create the RLE\n",
    "        \n",
    "    Returns:\n",
    "        RLE string\n",
    "    \n",
    "    \"\"\"\n",
    "    dots = np.where(img.T.flatten() == mask_val)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "        \n",
    "    return ' '.join([str(x) for x in run_lengths])\n",
    "\n",
    "\n",
    "def rle_to_mask(rle_string, height, width):\n",
    "    \"\"\" Convert RLE sttring into a binary mask \n",
    "    \n",
    "    Args:\n",
    "        rle_string (rle_string): Run length encoding containing \n",
    "            segmentation mask information\n",
    "        height (int): Height of the original image the map comes from\n",
    "        width (int): Width of the original image the map comes from\n",
    "    \n",
    "    Returns:\n",
    "        Numpy array of the binary segmentation mask for a given cell\n",
    "    \"\"\"\n",
    "    rows,cols = height,width\n",
    "    rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n",
    "    rle_pairs = np.array(rle_numbers).reshape(-1,2)\n",
    "    img = np.zeros(rows*cols,dtype=np.uint8)\n",
    "    for index,length in rle_pairs:\n",
    "        index -= 1\n",
    "        img[index:index+length] = 255\n",
    "    img = img.reshape(cols,rows)\n",
    "    img = img.T\n",
    "    return img\n",
    "\n",
    "\n",
    "def decode_img(img, img_size=(224,224), testing=False):\n",
    "    \"\"\"TBD\"\"\"\n",
    "    \n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    if not testing:\n",
    "        # resize the image to the desired size\n",
    "        img = tf.image.decode_png(img, channels=1)\n",
    "        return tf.cast(tf.image.resize(img, img_size), tf.uint8)\n",
    "    else:\n",
    "        return tf.image.decode_png(img, channels=1)\n",
    "        \n",
    "\n",
    "    \n",
    "def preprocess_path_ds(rp, gp, bp, yp, lbl, n_classes=19, img_size=(224,224), combine=True, drop_yellow=True):\n",
    "    \"\"\" TBD \"\"\"\n",
    "    \n",
    "    ri = decode_img(tf.io.read_file(rp), img_size)\n",
    "    gi = decode_img(tf.io.read_file(gp), img_size)\n",
    "    bi = decode_img(tf.io.read_file(bp), img_size)\n",
    "    yi = decode_img(tf.io.read_file(yp), img_size)\n",
    "\n",
    "    if combine and drop_yellow:\n",
    "        return tf.stack([ri[..., 0], gi[..., 0], bi[..., 0]], axis=-1), tf.one_hot(lbl, n_classes, dtype=tf.uint8)\n",
    "    elif combine:\n",
    "        return tf.stack([ri[..., 0], gi[..., 0], bi[..., 0], yi[..., 0]], axis=-1), tf.one_hot(lbl, n_classes, dtype=tf.uint8)\n",
    "    elif drop_yellow:\n",
    "        return ri, gi, bi, tf.one_hot(lbl, n_classes, dtype=tf.uint8)\n",
    "    else:\n",
    "        return ri, gi, bi, yi, tf.one_hot(lbl, n_classes, dtype=tf.uint8)        \n",
    "    \n",
    "    \n",
    "def create_pred_col(row):\n",
    "    \"\"\" Simple function to return the correct prediction string\n",
    "    \n",
    "    We will want the original public test dataframe submission when it is \n",
    "    available. However, we will use the swapped inn submission dataframe\n",
    "    when it is not.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): A row in the dataframe\n",
    "    \n",
    "    Returns:\n",
    "        The prediction string\n",
    "    \"\"\"\n",
    "    if pd.isnull(row.PredictionString_y):\n",
    "        return row.PredictionString_x\n",
    "    else:\n",
    "        return row.PredictionString_y\n",
    "    \n",
    "    \n",
    "def load_image(img_id, img_dir, testing=False, only_public=False):\n",
    "    \"\"\" Load An Image Using ID and Directory Path - Composes 4 Individual Images \"\"\"\n",
    "    if only_public:\n",
    "        return_axis = -1\n",
    "        clr_list = [\"red\", \"green\", \"blue\"]\n",
    "    else:\n",
    "        return_axis = 0\n",
    "        clr_list = [\"red\", \"green\", \"blue\", \"yellow\"]\n",
    "    \n",
    "    if not testing:\n",
    "        rgby = [\n",
    "            np.asarray(Image.open(os.path.join(img_dir, img_id+f\"_{c}.png\")), np.uint8) \\\n",
    "            for c in [\"red\", \"green\", \"blue\", \"yellow\"]\n",
    "        ]\n",
    "        return np.stack(rgby, axis=-1)\n",
    "    else:\n",
    "        # This is for cellsegmentator\n",
    "        return np.stack(\n",
    "            [np.asarray(decode_img(tf.io.read_file(os.path.join(img_dir, img_id+f\"_{c}.png\")), testing=True), np.uint8)[..., 0] \\\n",
    "             for c in clr_list], axis=return_axis,\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "def plot_rgb(arr, figsize=(12,12)):\n",
    "    \"\"\" Plot 3 Channel Microscopy Image \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(f\"RGB Composite Image\", fontweight=\"bold\")\n",
    "    plt.imshow(arr)\n",
    "    plt.axis(False)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def convert_rgby_to_rgb(arr):\n",
    "    \"\"\" Convert a 4 channel (RGBY) image to a 3 channel RGB image.\n",
    "    \n",
    "    Advice From Competition Host/User: lnhtrang\n",
    "\n",
    "    For annotation (by experts) and for the model, I guess we agree that individual \n",
    "    channels with full range px values are better. \n",
    "    In annotation, we toggled the channels. \n",
    "    For visualization purpose only, you can try blending the channels. \n",
    "    For example, \n",
    "        - red = red + yellow\n",
    "        - green = green + yellow/2\n",
    "        - blue=blue.\n",
    "        \n",
    "    Args:\n",
    "        arr (numpy array): The RGBY, 4 channel numpy array for a given image\n",
    "    \n",
    "    Returns:\n",
    "        RGB Image\n",
    "    \"\"\"\n",
    "    \n",
    "    rgb_arr = np.zeros_like(arr[..., :-1])\n",
    "    rgb_arr[..., 0] = arr[..., 0]\n",
    "    rgb_arr[..., 1] = arr[..., 1]+arr[..., 3]/2\n",
    "    rgb_arr[..., 2] = arr[..., 2]\n",
    "    \n",
    "    return rgb_arr\n",
    "    \n",
    "    \n",
    "def plot_ex(arr, figsize=(20,6), title=None, plot_merged=True, rgb_only=False):\n",
    "    \"\"\" Plot 4 Channels Side by Side \"\"\"\n",
    "    if plot_merged and not rgb_only:\n",
    "        n_images=5 \n",
    "    elif plot_merged and rgb_only:\n",
    "        n_images=4\n",
    "    elif not plot_merged and rgb_only:\n",
    "        n_images=4\n",
    "    else:\n",
    "        n_images=3\n",
    "    plt.figure(figsize=figsize)\n",
    "    if type(title) == str:\n",
    "        plt.suptitle(title, fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "    for i, c in enumerate([\"Red Channel – Microtubles\", \"Green Channel – Protein of Interest\", \"Blue - Nucleus\", \"Yellow – Endoplasmic Reticulum\"]):\n",
    "        if not rgb_only:\n",
    "            ch_arr = np.zeros_like(arr[..., :-1])        \n",
    "        else:\n",
    "            ch_arr = np.zeros_like(arr)\n",
    "        if c in [\"Red Channel – Microtubles\", \"Green Channel – Protein of Interest\", \"Blue - Nucleus\"]:\n",
    "            ch_arr[..., i] = arr[..., i]\n",
    "        else:\n",
    "            if rgb_only:\n",
    "                continue\n",
    "            ch_arr[..., 0] = arr[..., i]\n",
    "            ch_arr[..., 1] = arr[..., i]\n",
    "        plt.subplot(1,n_images,i+1)\n",
    "        plt.title(f\"{c.title()}\", fontweight=\"bold\")\n",
    "        plt.imshow(ch_arr)\n",
    "        plt.axis(False)\n",
    "        \n",
    "    if plot_merged:\n",
    "        plt.subplot(1,n_images,n_images)\n",
    "        \n",
    "        if rgb_only:\n",
    "            plt.title(f\"Merged RGB\", fontweight=\"bold\")\n",
    "            plt.imshow(arr)\n",
    "        else:\n",
    "            plt.title(f\"Merged RGBY into RGB\", fontweight=\"bold\")\n",
    "            plt.imshow(convert_rgby_to_rgb(arr))\n",
    "        plt.axis(False)\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0.2, 1, 0.97])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def flatten_list_of_lists(l_o_l, to_string=False):\n",
    "    if not to_string:\n",
    "        return [item for sublist in l_o_l for item in sublist]\n",
    "    else:\n",
    "        return [str(item) for sublist in l_o_l for item in sublist]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_contour_bbox_from_raw(raw_mask):\n",
    "    \"\"\" Get bbox of contour as `xmin ymin xmax ymax`\n",
    "    \n",
    "    Args:\n",
    "        raw_mask (nparray): Numpy array containing segmentation mask information\n",
    "    \n",
    "    Returns:\n",
    "        Numpy array for a cell bounding box coordinates\n",
    "    \"\"\"\n",
    "    cnts = grab_contours(\n",
    "        cv2.findContours(\n",
    "            raw_mask, \n",
    "            cv2.RETR_EXTERNAL, \n",
    "            cv2.CHAIN_APPROX_SIMPLE\n",
    "        ))\n",
    "    xywhs = [cv2.boundingRect(cnt) for cnt in cnts]\n",
    "    xys = [(xywh[0], xywh[1], xywh[0]+xywh[2], xywh[1]+xywh[3]) for xywh in xywhs]\n",
    "    return sorted(xys, key=lambda x: (x[1], x[0]))\n",
    "\n",
    "\n",
    "def pad_to_square(a):\n",
    "    \"\"\" Pad an array `a` evenly until it is a square \"\"\"\n",
    "    if a.shape[1]>a.shape[0]: # pad height\n",
    "        n_to_add = a.shape[1]-a.shape[0]\n",
    "        top_pad = n_to_add//2\n",
    "        bottom_pad = n_to_add-top_pad\n",
    "        a = np.pad(a, [(top_pad, bottom_pad), (0, 0), (0, 0)], mode='constant')\n",
    "\n",
    "    elif a.shape[0]>a.shape[1]: # pad width\n",
    "        n_to_add = a.shape[0]-a.shape[1]\n",
    "        left_pad = n_to_add//2\n",
    "        right_pad = n_to_add-left_pad\n",
    "        a = np.pad(a, [(0, 0), (left_pad, right_pad), (0, 0)], mode='constant')\n",
    "    else:\n",
    "        pass\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "def grab_contours(cnts):\n",
    "    # if the length the contours tuple returned by cv2.findContours\n",
    "    # is '2' then we are using either OpenCV v2.4, v4-beta, or\n",
    "    # v4-official\n",
    "    if len(cnts) == 2:\n",
    "        cnts = cnts[0]\n",
    "\n",
    "    # if the length of the contours tuple is '3' then we are using\n",
    "    # either OpenCV v3, v4-pre, or v4-alpha\n",
    "    elif len(cnts) == 3:\n",
    "        cnts = cnts[1]\n",
    "\n",
    "    # otherwise OpenCV has changed their cv2.findContours return\n",
    "    # signature yet again and I have no idea WTH is going on\n",
    "    else:\n",
    "        raise Exception((\"Contours tuple must have length 2 or 3, \"\n",
    "            \"otherwise OpenCV changed their cv2.findContours return \"\n",
    "            \"signature yet again. Refer to OpenCV's documentation \"\n",
    "            \"in that case\"))\n",
    "\n",
    "    # return the actual contours array\n",
    "    return cnts\n",
    "\n",
    "\n",
    "    \n",
    "def plot_predictions(img, masks, preds, confs=None, fill_alpha=0.3, lbl_as_str=True):\n",
    "    # Initialize\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX; FONT_SCALE = 0.7; FONT_THICKNESS = 2; FONT_LINE_TYPE = cv2.LINE_AA;\n",
    "    COLORS = [[round(y*255) for y in x] for x in sns.color_palette(\"Spectral\", len(LBL_NAMES))]\n",
    "    to_plot = img.copy()\n",
    "    cntr_img = img.copy()\n",
    "    if confs==None:\n",
    "        confs = [None,]*len(masks)\n",
    "\n",
    "    cnts = grab_contours(\n",
    "        cv2.findContours(\n",
    "            masks, \n",
    "            cv2.RETR_EXTERNAL, \n",
    "            cv2.CHAIN_APPROX_SIMPLE\n",
    "        ))\n",
    "    cnts = sorted(cnts, key=lambda x: (cv2.boundingRect(x)[1], cv2.boundingRect(x)[0]))\n",
    "        \n",
    "    for c, pred, conf in zip(cnts, preds, confs):\n",
    "        # We can only display one color so we pick the first\n",
    "        color = COLORS[pred[0]]\n",
    "        if not lbl_as_str:\n",
    "            classes = \"CLS=[\"+\",\".join([str(p) for p in pred])+\"]\"\n",
    "        else:\n",
    "            classes = \", \".join([INT_2_STR[p] for p in pred])\n",
    "        M = cv2.moments(c)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        \n",
    "        text_width, text_height = cv2.getTextSize(classes, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n",
    "        \n",
    "        # Border and fill\n",
    "        cv2.drawContours(to_plot, [c], contourIdx=-1, color=[max(0, x-40) for x in color], thickness=10)\n",
    "        cv2.drawContours(cntr_img, [c], contourIdx=-1, color=(color), thickness=-1)\n",
    "        \n",
    "        # Text\n",
    "        cv2.putText(to_plot, classes, (cx-text_width//2,cy-text_height//2),\n",
    "                    FONT, FONT_SCALE, [min(255, x+40) for x in color], FONT_THICKNESS, FONT_LINE_TYPE)\n",
    "    \n",
    "    cv2.addWeighted(cntr_img, fill_alpha, to_plot, 1-fill_alpha, 0, to_plot)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.imshow(to_plot)\n",
    "    plt.axis(False)\n",
    "    plt.show()\n",
    "    \n",
    "# def tta(original_img_batch, repeats=4):\n",
    "#     \"\"\" Perform test time augmentation \"\"\"\n",
    "#     tta_img_batches = [original_img_batch,]\n",
    "\n",
    "#     for i in range(repeats):\n",
    "#         # create new image batch (tf automatically deep copies)\n",
    "#         img_batch = original_img_batch\n",
    "        \n",
    "#         SEED = tf.random.uniform((2,), minval=0, maxval=100, dtype=tf.dtypes.int32)\n",
    "#         K = tf.random.uniform((1,), minval=0, maxval=4, dtype=tf.dtypes.int32)[0]\n",
    "\n",
    "#         img_batch = tf.image.stateless_random_flip_left_right(img_batch, SEED)\n",
    "#         img_batch = tf.image.stateless_random_flip_up_down(img_batch, SEED)\n",
    "#         img_batch = tf.image.rot90(img_batch, K)\n",
    "\n",
    "#         img_batch = tf.image.stateless_random_saturation(img_batch, 0.9, 1.1, SEED)\n",
    "#         img_batch = tf.image.stateless_random_brightness(img_batch, 0.075, SEED)\n",
    "#         img_batch = tf.image.stateless_random_contrast(img_batch, 0.9, 1.1, SEED)    \n",
    "#         tta_img_batches.append(img_batch)\n",
    "    \n",
    "#     return tta_img_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T13:29:04.927152Z",
     "iopub.status.busy": "2021-05-09T13:29:04.926443Z",
     "iopub.status.idle": "2021-05-09T13:29:19.686493Z",
     "shell.execute_reply": "2021-05-09T13:29:19.685848Z"
    },
    "papermill": {
     "duration": 14.779793,
     "end_time": "2021-05-09T13:29:19.686657",
     "exception": false,
     "start_time": "2021-05-09T13:29:04.906864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please compile abn\n"
     ]
    }
   ],
   "source": [
    "# Load Segmentator\n",
    "segmentator = cellsegmentator.CellSegmentator(NUC_MODEL, CELL_MODEL, scale_factor=0.25, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T13:29:19.734032Z",
     "iopub.status.busy": "2021-05-09T13:29:19.732564Z",
     "iopub.status.idle": "2021-05-09T13:29:47.056239Z",
     "shell.execute_reply": "2021-05-09T13:29:47.055605Z"
    },
    "papermill": {
     "duration": 27.352862,
     "end_time": "2021-05-09T13:29:47.056411",
     "exception": false,
     "start_time": "2021-05-09T13:29:19.703549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load inference model\n",
    "inference_model = tf.keras.models.load_model(B2_CELL_CLSFR_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T13:29:47.098825Z",
     "iopub.status.busy": "2021-05-09T13:29:47.097142Z",
     "iopub.status.idle": "2021-05-09T13:29:47.099584Z",
     "shell.execute_reply": "2021-05-09T13:29:47.100189Z"
    },
    "papermill": {
     "duration": 0.027805,
     "end_time": "2021-05-09T13:29:47.100409",
     "exception": false,
     "start_time": "2021-05-09T13:29:47.072604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMAGE_SIZES = [1728, 2048, 3072, 4096]\n",
    "BATCH_SIZE = 16\n",
    "CONF_THRESH = 0.0\n",
    "TILE_SIZE = (300,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T13:29:47.142871Z",
     "iopub.status.busy": "2021-05-09T13:29:47.142182Z",
     "iopub.status.idle": "2021-05-09T13:29:47.170785Z",
     "shell.execute_reply": "2021-05-09T13:29:47.169623Z"
    },
    "papermill": {
     "duration": 0.051937,
     "end_time": "2021-05-09T13:29:47.170979",
     "exception": false,
     "start_time": "2021-05-09T13:29:47.119042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make subset dataframes\n",
    "predict_df_1728 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[0]]\n",
    "predict_df_2048 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[1]]\n",
    "predict_df_3072 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[2]]\n",
    "predict_df_4096 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[3]]\n",
    "\n",
    "\n",
    "predict_ids_1728 = predict_df_1728.ID.to_list()\n",
    "predict_ids_2048 = predict_df_2048.ID.to_list()\n",
    "predict_ids_3072 = predict_df_3072.ID.to_list()\n",
    "predict_ids_4096 = predict_df_4096.ID.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T13:29:47.212857Z",
     "iopub.status.busy": "2021-05-09T13:29:47.211874Z",
     "iopub.status.idle": "2021-05-09T13:29:47.217358Z",
     "shell.execute_reply": "2021-05-09T13:29:47.216681Z"
    },
    "papermill": {
     "duration": 0.029787,
     "end_time": "2021-05-09T13:29:47.217532",
     "exception": false,
     "start_time": "2021-05-09T13:29:47.187745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(network_path, arch='class_densenet121_dropout', \n",
    "               num_classes=19, in_channels=4):\n",
    "    model_params = {}\n",
    "    model_params['architecture'] = arch\n",
    "    model_params['num_classes'] = num_classes\n",
    "    model_params['in_channels'] = in_channels\n",
    "    model = init_network(model_params)\n",
    "\n",
    "    checkpoint = torch.load(network_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T13:29:47.269298Z",
     "iopub.status.busy": "2021-05-09T13:29:47.268515Z",
     "iopub.status.idle": "2021-05-09T13:29:50.306817Z",
     "shell.execute_reply": "2021-05-09T13:29:50.306199Z"
    },
    "papermill": {
     "duration": 3.072431,
     "end_time": "2021-05-09T13:29:50.307005",
     "exception": false,
     "start_time": "2021-05-09T13:29:47.234574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using pre-trained model.\n"
     ]
    }
   ],
   "source": [
    "RESULT_DIR = Path('/kaggle/input/humanpro-classifier-4/results')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "out_dir = ('external_crop256_focal_slov_hardlog_class'\n",
    "           '_densenet121_dropout_i384_aug2_5folds')\n",
    "predict_epoch = 9\n",
    "fold = 0\n",
    "arch = 'class_densenet121_dropout'\n",
    "predict_epoch = 'final' if predict_epoch is None else '%03d' % predict_epoch\n",
    "network_path = RESULT_DIR/'models'/out_dir/f'fold{fold:d}'/f'{predict_epoch}.pth'\n",
    "\n",
    "model = load_model(network_path, arch=arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T13:29:50.371469Z",
     "iopub.status.busy": "2021-05-09T13:29:50.358213Z",
     "iopub.status.idle": "2021-05-09T13:31:12.933592Z",
     "shell.execute_reply": "2021-05-09T13:31:12.928498Z"
    },
    "papermill": {
     "duration": 82.608443,
     "end_time": "2021-05-09T13:31:12.933828",
     "exception": false,
     "start_time": "2021-05-09T13:29:50.325385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...WORKING ON IMAGE IDS FOR SIZE 1728 ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43696b337904b12b17ab36478b6d2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...WORKING ON IMAGE IDS FOR SIZE 2048 ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10caa7ca04c74a0985921461e959a28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...WORKING ON IMAGE IDS FOR SIZE 3072 ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8aaf76d65224ca583cad0969df5a070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...SKIPPING SIZE 4096 AS THERE ARE NO IMAGE IDS ...\n",
      "\n",
      "\n",
      "... TEST DATAFRAME ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>020a29cf-2c24-478b-8603-c22a90dc3e31</td>\n",
       "      <td>0 0.0078 eNq1l2l74kYMgP+SZQxsth/bslyW73t8jQ98Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>0 0.1135 eNqFUNsOgjAM/aV1XMQ/gOHa4P1BECTGS4L+/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>0 0.0549 eNq1Vm2TmjAQ/ksuyfU67fRD+6EzXnABRd5ER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "0  020a29cf-2c24-478b-8603-c22a90dc3e31   \n",
       "1  fea47298-266a-4cf4-93bd-55d1bcc2fc7d   \n",
       "2  0040581b-f1f2-4fbe-b043-b6bfea5404bb   \n",
       "\n",
       "                                    PredictionString  \n",
       "0  0 0.0078 eNq1l2l74kYMgP+SZQxsth/bslyW73t8jQ98Y...  \n",
       "1  0 0.1135 eNqFUNsOgjAM/aV1XMQ/gOHa4P1BECTGS4L+/...  \n",
       "2  0 0.0549 eNq1Vm2TmjAQ/ksuyfU67fRD+6EzXnABRd5ER...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "sub_df = pd.DataFrame(columns=[\"ID\"], \n",
    "                      data=predict_ids_1728+predict_ids_2048+predict_ids_3072+predict_ids_4096)\n",
    "\n",
    "for size_idx, submission_ids in enumerate([predict_ids_1728, predict_ids_2048, \n",
    "                                           predict_ids_3072, predict_ids_4096]):\n",
    "    size = IMAGE_SIZES[size_idx]\n",
    "    if submission_ids==[]:\n",
    "        print(f\"\\n...SKIPPING SIZE {size} AS THERE ARE NO IMAGE IDS ...\\n\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"\\n...WORKING ON IMAGE IDS FOR SIZE {size} ...\\n\")\n",
    "        \n",
    "    for i in tqdm(range(0, len(submission_ids), BATCH_SIZE), \n",
    "                  total=int(np.ceil(len(submission_ids)/BATCH_SIZE))):\n",
    " \n",
    "        batch_rgby_images = [load_image(ID, TEST_IMG_DIR, testing=True, only_public=False)\n",
    "                             for ID in submission_ids[i:(i+BATCH_SIZE)]]\n",
    "        batch_rgb_images = [rgby_image.transpose(1,2,0)[..., :-1] for rgby_image in batch_rgby_images]\n",
    "        \n",
    "        cell_segmentations = segmentator.pred_cells([[rgby_image[j] for rgby_image in batch_rgby_images] \n",
    "                                                     for j in [0, 3, 2]])\n",
    "        nuc_segmentations = segmentator.pred_nuclei([rgby_image[2] for rgby_image in batch_rgby_images])\n",
    "        batch_masks = [label_cell(nuc_seg, cell_seg)[1].astype(np.uint8) \n",
    "                       for nuc_seg, cell_seg in zip(nuc_segmentations, cell_segmentations)]\n",
    "\n",
    "        batch_cell_bboxes = [get_contour_bbox_from_raw(mask) for mask in batch_masks]\n",
    "        submission_rles = [[binary_mask_to_ascii(mask, mask_val=cell_id) for cell_id in range(1, mask.max()+1)] \n",
    "                           for mask in batch_masks]\n",
    "    \n",
    "        batch_cell_tiles_rgby = [\n",
    "            [cv2.resize(\n",
    "                pad_to_square(rgby_image.transpose(1, 2, 0)[bbox[1]:bbox[3], bbox[0]:bbox[2], ...]), \n",
    "                TILE_SIZE, interpolation=cv2.INTER_CUBIC) for bbox in bboxes]\n",
    "            for bboxes, rgby_image in zip(batch_cell_bboxes, batch_rgby_images)]\n",
    "        batch_cell_tiles_rgby = [[torch.from_numpy(ct / 255).type(torch.float32) for ct in cts] \n",
    "                                 for cts in batch_cell_tiles_rgby]\n",
    "        batch_cell_tiles_rgby = [torch.stack(cts, axis=0).permute(0, 3, 1, 2) \n",
    "                                 for cts in batch_cell_tiles_rgby]\n",
    "        with torch.no_grad():\n",
    "            batch_o_preds_rgby = [F.sigmoid(model(cts.to(DEVICE))).cpu().numpy() \n",
    "                                  for cts in batch_cell_tiles_rgby]\n",
    "    \n",
    "\n",
    "#         batch_cell_tiles = [[\n",
    "#             cv2.resize(\n",
    "#                 pad_to_square(\n",
    "#                     rgb_image[bbox[1]:bbox[3], bbox[0]:bbox[2], ...]), \n",
    "#                 TILE_SIZE, interpolation=cv2.INTER_CUBIC) for bbox in bboxes] \n",
    "#             for bboxes, rgb_image in zip(batch_cell_bboxes, batch_rgb_images)\n",
    "#         ]\n",
    "#         batch_cell_tiles = [tf.cast(ct, dtype=tf.float32) for ct in batch_cell_tiles]\n",
    "#         batch_o_preds = [inference_model.predict(cell_tiles) for cell_tiles in batch_cell_tiles]\n",
    "        batch_o_preds = batch_o_preds_rgby[:]\n",
    "        \n",
    "        # Step 9: Post-Process\n",
    "        batch_confs = [[pred[np.where(pred>CONF_THRESH)] for pred in o_preds] for o_preds in batch_o_preds]\n",
    "        batch_preds = [[np.where(pred>CONF_THRESH)[0] for pred in o_preds] for o_preds in batch_o_preds]\n",
    "\n",
    "        for j, preds in enumerate(batch_preds):\n",
    "            for k in range(len(preds)):\n",
    "                if preds[k].size==0:\n",
    "                    batch_preds[j][k]=np.array([18,])\n",
    "                    batch_confs[j][k]=np.array([1-np.max(batch_o_preds[j][k]),])\n",
    "        \n",
    "        # Optional Viz Step\n",
    "#         if IS_DEMO:\n",
    "#             print(':D')\n",
    "#             print(\"\\n... DEMO IMAGES ...\\n\")\n",
    "#             for rgb_images, masks, preds, confs in zip(batch_rgb_images, batch_masks, batch_preds, batch_confs):\n",
    "#                 plot_predictions(rgb_images, masks, preds, confs=confs, fill_alpha=0.2, lbl_as_str=True)\n",
    "\n",
    "        \n",
    "        # Step 10: Format Predictions To Create Prediction String Easily\n",
    "        submission_rles = [flatten_list_of_lists([[m,]*len(p) for m, p in zip(masks, preds)]) \n",
    "                           for masks, preds in zip(submission_rles, batch_preds)]\n",
    "        batch_preds = [flatten_list_of_lists(preds, to_string=True) for preds in batch_preds]\n",
    "        batch_confs = [[f\"{conf:.4f}\" for cell_confs in confs for conf in cell_confs] for confs in batch_confs]\n",
    "        \n",
    "        # Step 11: Save Predictions to Be Added to Dataframe At The End\n",
    "        predictions.extend([\" \".join(flatten_list_of_lists(zip(*[preds,confs,masks]))) for preds, confs, masks in zip(batch_preds, batch_confs, submission_rles)])\n",
    "sub_df[\"PredictionString\"] = predictions\n",
    "\n",
    "print(\"\\n... TEST DATAFRAME ...\\n\")\n",
    "display(sub_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T13:31:12.990257Z",
     "iopub.status.busy": "2021-05-09T13:31:12.989140Z",
     "iopub.status.idle": "2021-05-09T13:31:13.187294Z",
     "shell.execute_reply": "2021-05-09T13:31:13.187859Z"
    },
    "papermill": {
     "duration": 0.232628,
     "end_time": "2021-05-09T13:31:13.188071",
     "exception": false,
     "start_time": "2021-05-09T13:31:12.955443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0549 eNq1Vm2TmjAQ/ksuyfU67fRD+6EzXnABRd5ER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0173029a-161d-40ef-af28-2342915b22fb</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 0.0488 eNqVVN16sjAMvqUS9JOnx+PDTUOdTsEW/IMK/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>020a29cf-2c24-478b-8603-c22a90dc3e31</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 0.0078 eNq1l2l74kYMgP+SZQxsth/bslyW73t8jQ98Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 0.1135 eNqFUNsOgjAM/aV1XMQ/gOHa4P1BECTGS4L+/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ff069fa2-d948-408e-91b3-034cfea428d1</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 0.0882 eNq9VVlvwjAM/kupE9ghoe1h4mqcsKkr1cTYO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ff23eea9-4bbe-42af-a8da-9ae16321fc6d</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0043 eNqdkt2OmzAQhV/JB9IGbbutmnaLtg0D+SEJD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  ImageWidth  ImageHeight  \\\n",
       "0  0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
       "1  0173029a-161d-40ef-af28-2342915b22fb        3072         3072   \n",
       "2  020a29cf-2c24-478b-8603-c22a90dc3e31        1728         1728   \n",
       "3  fea47298-266a-4cf4-93bd-55d1bcc2fc7d        1728         1728   \n",
       "4  ff069fa2-d948-408e-91b3-034cfea428d1        3072         3072   \n",
       "5  ff23eea9-4bbe-42af-a8da-9ae16321fc6d        2048         2048   \n",
       "\n",
       "                                    PredictionString  \n",
       "0  0 0.0549 eNq1Vm2TmjAQ/ksuyfU67fRD+6EzXnABRd5ER...  \n",
       "1  0 0.0488 eNqVVN16sjAMvqUS9JOnx+PDTUOdTsEW/IMK/...  \n",
       "2  0 0.0078 eNq1l2l74kYMgP+SZQxsth/bslyW73t8jQ98Y...  \n",
       "3  0 0.1135 eNqFUNsOgjAM/aV1XMQ/gOHa4P1BECTGS4L+/...  \n",
       "4  0 0.0882 eNq9VVlvwjAM/kupE9ghoe1h4mqcsKkr1cTYO...  \n",
       "5  0 0.0043 eNqdkt2OmzAQhV/JB9IGbbutmnaLtg0D+SEJD...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss_df = ss_df.merge(sub_df, how=\"left\", on=\"ID\")\n",
    "ss_df[\"PredictionString\"] = ss_df.apply(create_pred_col, axis=1)\n",
    "ss_df = ss_df.drop(columns=[\"PredictionString_x\", \"PredictionString_y\"])\n",
    "ss_df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "display(ss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.021093,
     "end_time": "2021-05-09T13:31:13.230579",
     "exception": false,
     "start_time": "2021-05-09T13:31:13.209486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 276.429559,
   "end_time": "2021-05-09T13:31:18.846359",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-09T13:26:42.416800",
   "version": "2.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0504f559cc144518810e3173f721a223": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0b0ef0875ca44b6b8147f387bc41e564": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "10caa7ca04c74a0985921461e959a28e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eaf68eea6ac9427486a7782364b4db03",
        "IPY_MODEL_7030b38ace574828a900ba23d554539a",
        "IPY_MODEL_2f7709a6d0e94d6badf223a71f3cae5b"
       ],
       "layout": "IPY_MODEL_34f55e8153cf438aaa570cfa5f7d3e1c"
      }
     },
     "1bc281889afa4abc872b16621b78f34b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7d7e0bc015004930aa7c08a304fcd715",
       "placeholder": "​",
       "style": "IPY_MODEL_5b9e0cb1b04c43b19692d79f0e93e37d",
       "value": "100%"
      }
     },
     "1fe84ddc13c34806905ca04195b72994": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a606c00c09b24ab0b5cf6189814e2046",
       "placeholder": "​",
       "style": "IPY_MODEL_0b0ef0875ca44b6b8147f387bc41e564",
       "value": " 1/1 [00:14&lt;00:00, 14.40s/it]"
      }
     },
     "267f64fd14fa44b19ef8c2240278a2a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_356bf56d037243c68cf1d166053a9671",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6f53ab2186c64a6ab03725b6094d719e",
       "value": 1.0
      }
     },
     "275640d17c8849b9a1adb7eb0d5e93a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ebbecbd58b3d4c1dbe33bde9f64a2083",
       "placeholder": "​",
       "style": "IPY_MODEL_b2a2e5c145a54eb3895e0e8a971ba30d",
       "value": "100%"
      }
     },
     "2f7709a6d0e94d6badf223a71f3cae5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e5eb3f5818da4f6e898db14a65880972",
       "placeholder": "​",
       "style": "IPY_MODEL_60f3a64da4104aa89b22e2a1aaa72ed3",
       "value": " 1/1 [00:20&lt;00:00, 20.67s/it]"
      }
     },
     "34f55e8153cf438aaa570cfa5f7d3e1c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "356bf56d037243c68cf1d166053a9671": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "396851e979474493807a58c3f23765a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3ca42e05674e41e680249b5078611376": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b9e0cb1b04c43b19692d79f0e93e37d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "60f3a64da4104aa89b22e2a1aaa72ed3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6dced87f236b46beaf271c0ab98872c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f53ab2186c64a6ab03725b6094d719e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7030b38ace574828a900ba23d554539a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6dced87f236b46beaf271c0ab98872c8",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_396851e979474493807a58c3f23765a3",
       "value": 1.0
      }
     },
     "7d7e0bc015004930aa7c08a304fcd715": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "948f339f867d42af918e127c816b007a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "965fc725f2a04112a9abbe07dd77a78d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a606c00c09b24ab0b5cf6189814e2046": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2a2e5c145a54eb3895e0e8a971ba30d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b6807a0bf8cc4fbbbc42ef69ee3eb12e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3ca42e05674e41e680249b5078611376",
       "placeholder": "​",
       "style": "IPY_MODEL_965fc725f2a04112a9abbe07dd77a78d",
       "value": " 1/1 [00:47&lt;00:00, 47.42s/it]"
      }
     },
     "c97a332b503d4215a961c2dad4255d38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e8f90b3724ce4963b5f90a172671d78f",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fdc9627fc57e4030ae12738df33d9918",
       "value": 1.0
      }
     },
     "d3b29f16489048b8bbdf2652691ae711": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d43696b337904b12b17ab36478b6d2b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_275640d17c8849b9a1adb7eb0d5e93a5",
        "IPY_MODEL_c97a332b503d4215a961c2dad4255d38",
        "IPY_MODEL_1fe84ddc13c34806905ca04195b72994"
       ],
       "layout": "IPY_MODEL_d463aebf08084c5e95acf948cbd6c254"
      }
     },
     "d463aebf08084c5e95acf948cbd6c254": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5eb3f5818da4f6e898db14a65880972": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8f90b3724ce4963b5f90a172671d78f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eaf68eea6ac9427486a7782364b4db03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_948f339f867d42af918e127c816b007a",
       "placeholder": "​",
       "style": "IPY_MODEL_0504f559cc144518810e3173f721a223",
       "value": "100%"
      }
     },
     "ebbecbd58b3d4c1dbe33bde9f64a2083": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8aaf76d65224ca583cad0969df5a070": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1bc281889afa4abc872b16621b78f34b",
        "IPY_MODEL_267f64fd14fa44b19ef8c2240278a2a2",
        "IPY_MODEL_b6807a0bf8cc4fbbbc42ef69ee3eb12e"
       ],
       "layout": "IPY_MODEL_d3b29f16489048b8bbdf2652691ae711"
      }
     },
     "fdc9627fc57e4030ae12738df33d9918": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
