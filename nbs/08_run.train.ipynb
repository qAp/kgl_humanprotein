{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `run.train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on collie.local\n",
      "run on collie.local\n",
      "run on collie.local\n",
      "run on collie.local\n",
      "run on collie.local\n"
     ]
    }
   ],
   "source": [
    "#default_exp run.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "from torch.nn import DataParallel\n",
    "from torch.backends import cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from kgl_humanprotein.config.config import *\n",
    "from kgl_humanprotein.utils.common_util import *\n",
    "from kgl_humanprotein.data_process import generate_meta, create_random_split\n",
    "from kgl_humanprotein.networks.imageclsnet import init_network\n",
    "from kgl_humanprotein.datasets.protein_dataset import ProteinDataset\n",
    "from kgl_humanprotein.utils.augment_util import train_multi_augment2\n",
    "from kgl_humanprotein.layers.loss import *\n",
    "from kgl_humanprotein.layers.scheduler import *\n",
    "from kgl_humanprotein.utils.log_util import Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the subsets' meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def combine_subsets_metadata(dir_data, n_subsets=5):\n",
    "    df_cells = pd.DataFrame()\n",
    "    for isubset in range(n_subsets):\n",
    "        print(f'\\rProcessing subset {isubset}...', end='', flush=True)\n",
    "        pth_feather = (dir_data / \n",
    "                       f'humanpro-train-cells-subset{isubset}' /\n",
    "                       f'humanpro_train_cells_subset{isubset}' / 'train/train.feather')\n",
    "        \n",
    "        df = pd.read_feather(pth_feather)\n",
    "        df['subset'] = isubset\n",
    "        \n",
    "        df_cells = df_cells.append(df, ignore_index=True)\n",
    "    return df_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = Path('../../kgl_humanprotein_data')\n",
    "dir_mdata = Path('mdata')\n",
    "n_subsets = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subset 4...CPU times: user 28.5 ms, sys: 31.4 ms, total: 59.9 ms\n",
      "Wall time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_cells = combine_subsets_metadata(dir_data, n_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_mdata_raw = dir_mdata/'raw'\n",
    "dir_mdata_raw.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "df_cells.to_feather(dir_mdata_raw/'train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cells = pd.read_feather(dir_mdata_raw/'train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep single-label samples\n",
    "df_cells = (df_cells[df_cells['Target'].apply(lambda o: len(o.split('|'))==1)]\n",
    "            .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def cap_number_per_label(df_cells, cap=10_000, idx_start=0):\n",
    "    df_cells_cap = pd.DataFrame()\n",
    "    for label in df_cells.Target.unique():\n",
    "        df = df_cells[df_cells.Target==label]\n",
    "        if len(df) > cap:\n",
    "            df = df.iloc[idx_start:idx_start + cap]\n",
    "        df_cells_cap = df_cells_cap.append(df, ignore_index=True)\n",
    "    return df_cells_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit number of samples per label\n",
    "\n",
    "df_cells = cap_number_per_label(df_cells, cap=5_000, idx_start=5_000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     129\n",
       "10     70\n",
       "6      52\n",
       "3      39\n",
       "15     25\n",
       "9      17\n",
       "12     16\n",
       "5      16\n",
       "14     15\n",
       "13     15\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cells.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>rle</th>\n",
       "      <th>bbox</th>\n",
       "      <th>Target</th>\n",
       "      <th>max_green</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0877a7da-bba3-11e8-b2b9-ac1f6b6435d0_0</td>\n",
       "      <td>{'counts': b'^1P5Pk1000000O1O1O01000O01O0001O1...</td>\n",
       "      <td>[0, 0, 276, 206]</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0877a7da-bba3-11e8-b2b9-ac1f6b6435d0_1</td>\n",
       "      <td>{'counts': b'PPV:1oo12N1O1O3M2N00001O000000000...</td>\n",
       "      <td>[163, 0, 438, 325]</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0877a7da-bba3-11e8-b2b9-ac1f6b6435d0_2</td>\n",
       "      <td>{'counts': b'nTdm0=co11O1O1O000000000O2O000O2N...</td>\n",
       "      <td>[474, 0, 1250, 207]</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0877a7da-bba3-11e8-b2b9-ac1f6b6435d0_3</td>\n",
       "      <td>{'counts': b'fUj[21no12N4L1O2N2N2N&gt;B2M3N5K3K4M...</td>\n",
       "      <td>[1213, 0, 1766, 291]</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0877a7da-bba3-11e8-b2b9-ac1f6b6435d0_4</td>\n",
       "      <td>{'counts': b'WXTf11no12O1N2N2O1O1N4L3M2O1N2N3L...</td>\n",
       "      <td>[866, 147, 1494, 509]</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>f8d60850-bbbe-11e8-b2ba-ac1f6b6435d0_10</td>\n",
       "      <td>{'counts': b'[`_j02ko16L2N2L7L2N1O2M9H2N1N9H00...</td>\n",
       "      <td>[423, 1190, 1138, 1802]</td>\n",
       "      <td>14</td>\n",
       "      <td>223</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>f8d60850-bbbe-11e8-b2ba-ac1f6b6435d0_11</td>\n",
       "      <td>{'counts': b'V[1\\\\&lt;dc100O1N2O1O1O1O10000O10000...</td>\n",
       "      <td>[0, 1214, 390, 1778]</td>\n",
       "      <td>14</td>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>f8d60850-bbbe-11e8-b2ba-ac1f6b6435d0_12</td>\n",
       "      <td>{'counts': b'hge?`0_o12N2L6nMV2H2aUNPMkg1R3TXN...</td>\n",
       "      <td>[250, 1458, 682, 2018]</td>\n",
       "      <td>14</td>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>f8d60850-bbbe-11e8-b2ba-ac1f6b6435d0_13</td>\n",
       "      <td>{'counts': b'^ceV1:fo11O1O3M3L2O1O3L3M2N2O1O2N...</td>\n",
       "      <td>[618, 1642, 1210, 2048]</td>\n",
       "      <td>14</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>f8d60850-bbbe-11e8-b2ba-ac1f6b6435d0_14</td>\n",
       "      <td>{'counts': b'ni1R6ni10000000000000000000000000...</td>\n",
       "      <td>[0, 1842, 261, 2048]</td>\n",
       "      <td>14</td>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Id  \\\n",
       "0     0877a7da-bba3-11e8-b2b9-ac1f6b6435d0_0   \n",
       "1     0877a7da-bba3-11e8-b2b9-ac1f6b6435d0_1   \n",
       "2     0877a7da-bba3-11e8-b2b9-ac1f6b6435d0_2   \n",
       "3     0877a7da-bba3-11e8-b2b9-ac1f6b6435d0_3   \n",
       "4     0877a7da-bba3-11e8-b2b9-ac1f6b6435d0_4   \n",
       "..                                       ...   \n",
       "389  f8d60850-bbbe-11e8-b2ba-ac1f6b6435d0_10   \n",
       "390  f8d60850-bbbe-11e8-b2ba-ac1f6b6435d0_11   \n",
       "391  f8d60850-bbbe-11e8-b2ba-ac1f6b6435d0_12   \n",
       "392  f8d60850-bbbe-11e8-b2ba-ac1f6b6435d0_13   \n",
       "393  f8d60850-bbbe-11e8-b2ba-ac1f6b6435d0_14   \n",
       "\n",
       "                                                   rle  \\\n",
       "0    {'counts': b'^1P5Pk1000000O1O1O01000O01O0001O1...   \n",
       "1    {'counts': b'PPV:1oo12N1O1O3M2N00001O000000000...   \n",
       "2    {'counts': b'nTdm0=co11O1O1O000000000O2O000O2N...   \n",
       "3    {'counts': b'fUj[21no12N4L1O2N2N2N>B2M3N5K3K4M...   \n",
       "4    {'counts': b'WXTf11no12O1N2N2O1O1N4L3M2O1N2N3L...   \n",
       "..                                                 ...   \n",
       "389  {'counts': b'[`_j02ko16L2N2L7L2N1O2M9H2N1N9H00...   \n",
       "390  {'counts': b'V[1\\\\<dc100O1N2O1O1O1O10000O10000...   \n",
       "391  {'counts': b'hge?`0_o12N2L6nMV2H2aUNPMkg1R3TXN...   \n",
       "392  {'counts': b'^ceV1:fo11O1O3M3L2O1O3L3M2N2O1O2N...   \n",
       "393  {'counts': b'ni1R6ni10000000000000000000000000...   \n",
       "\n",
       "                        bbox Target  max_green  subset  \n",
       "0           [0, 0, 276, 206]      3        160       0  \n",
       "1         [163, 0, 438, 325]      3         71       0  \n",
       "2        [474, 0, 1250, 207]      3        255       0  \n",
       "3       [1213, 0, 1766, 291]      3        255       0  \n",
       "4      [866, 147, 1494, 509]      3        255       0  \n",
       "..                       ...    ...        ...     ...  \n",
       "389  [423, 1190, 1138, 1802]     14        223       4  \n",
       "390     [0, 1214, 390, 1778]     14        255       4  \n",
       "391   [250, 1458, 682, 2018]     14        255       4  \n",
       "392  [618, 1642, 1210, 2048]     14        200       4  \n",
       "393     [0, 1842, 261, 2048]     14        255       4  \n",
       "\n",
       "[394 rows x 6 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cells[df_cells.Target != '18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cells.to_feather(dir_mdata_raw/'train.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *bestfitting*'s code, this generates the \"meta\" files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 4.07 ms, total: 107 ms\n",
      "Wall time: 113 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate_meta(dir_mdata, 'train.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nucleoplasm 103 26\n",
      "Nuclear membrane 0 0\n",
      "Nucleoli 0 0\n",
      "Nucleoli fibrillar center 31 8\n",
      "Nuclear speckles 0 0\n",
      "Nuclear bodies 13 3\n",
      "Endoplasmic reticulum 42 10\n",
      "Golgi apparatus 0 0\n",
      "Intermediate filaments 0 0\n",
      "Actin filaments 14 3\n",
      "Microtubules 56 14\n",
      "Mitotic spindle 0 0\n",
      "Centrosome 12 4\n",
      "Plasma membrane 12 3\n",
      "Mitochondria 12 3\n",
      "Aggresome 20 5\n",
      "Cytosol 0 0\n",
      "Vesicles and punctate cytosolic patterns 0 0\n",
      "Negative 0 0\n",
      "create split file: mdata/split/random_folds5/random_train_cv0.feather, shape: (315, 27)\n",
      "create split file: mdata/split/random_folds5/random_valid_cv0.feather, shape: (79, 27)\n",
      "create split file: mdata/split/random_folds5/random_train_cv1.feather, shape: (315, 27)\n",
      "create split file: mdata/split/random_folds5/random_valid_cv1.feather, shape: (79, 27)\n",
      "create split file: mdata/split/random_folds5/random_train_cv2.feather, shape: (316, 27)\n",
      "create split file: mdata/split/random_folds5/random_valid_cv2.feather, shape: (78, 27)\n",
      "create split file: mdata/split/random_folds5/random_train_cv3.feather, shape: (315, 27)\n",
      "create split file: mdata/split/random_folds5/random_valid_cv3.feather, shape: (79, 27)\n",
      "create split file: mdata/split/random_folds5/random_train_cv4.feather, shape: (315, 27)\n",
      "create split file: mdata/split/random_folds5/random_valid_cv4.feather, shape: (79, 27)\n",
      "CPU times: user 74.8 ms, sys: 16.4 ms, total: 91.1 ms\n",
      "Wall time: 86.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_meta = pd.read_feather(dir_mdata/'meta'/'train_meta.feather')\n",
    "create_random_split(dir_mdata, train_meta, n_splits=5, alias='random')\n",
    "del train_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted random sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_label_weights(df):\n",
    "    '''\n",
    "    Weigh each label with the reciprocal of its probability of\n",
    "    appearance in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Meta data data-frame.\n",
    "    '''\n",
    "    value_counts = df['Target'].value_counts()\n",
    "    probs = value_counts / value_counts.sum()\n",
    "    weights = 1 / probs\n",
    "    return weights.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weighted_sampler():\n",
    "    dir_data = Path('../../kgl_humanprotein_data/')\n",
    "    train_split_file = dir_mdata/'split'/'random_folds5'/'random_train_cv0.feather'\n",
    "\n",
    "    train_dataset = ProteinDataset(dir_data, train_split_file)\n",
    "\n",
    "    label_weights = get_label_weights(train_dataset.split_df)\n",
    "    weights = torch.from_numpy(train_dataset.split_df['Target'].apply(lambda o: label_weights[o]).values)\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, sampler=sampler)\n",
    "    \n",
    "    print(label_weights)\n",
    "    print(train_dataset.split_df.Target.values)\n",
    "    print(train_loader.sampler.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 3.058252427184466, '10': 5.625, '6': 7.5, '3': 10.161290322580646, '15': 15.75, '9': 22.5, '5': 24.23076923076923, '13': 26.249999999999996, '12': 26.249999999999996, '14': 26.249999999999996}\n",
      "['3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
      " '3' '3' '3' '3' '3' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6'\n",
      " '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6'\n",
      " '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '9' '9' '9' '9' '9' '9' '9'\n",
      " '9' '9' '9' '9' '9' '9' '9' '13' '13' '13' '13' '13' '13' '13' '13' '13'\n",
      " '13' '13' '13' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '10' '10' '10' '10' '10' '10'\n",
      " '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10'\n",
      " '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10'\n",
      " '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10'\n",
      " '10' '10' '10' '10' '10' '10' '10' '10' '3' '3' '3' '3' '3' '3' '3' '3'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '12' '12' '12' '12' '12' '12' '12' '12' '12' '12' '12' '12' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '15' '15'\n",
      " '15' '15' '15' '15' '15' '15' '15' '15' '15' '15' '15' '15' '15' '15'\n",
      " '15' '15' '15' '15' '14' '14' '14' '14' '14' '14' '14' '14' '14' '14'\n",
      " '14' '14']\n",
      "tensor([10.1613, 10.1613, 10.1613, 10.1613, 10.1613, 10.1613, 10.1613, 10.1613,\n",
      "        10.1613, 10.1613, 10.1613, 10.1613, 10.1613, 10.1613, 10.1613, 10.1613,\n",
      "        10.1613, 10.1613, 10.1613, 10.1613, 10.1613, 10.1613, 10.1613,  7.5000,\n",
      "         7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,\n",
      "         7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,\n",
      "         7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,\n",
      "         7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,\n",
      "         7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,  7.5000,\n",
      "         7.5000, 22.5000, 22.5000, 22.5000, 22.5000, 22.5000, 22.5000, 22.5000,\n",
      "        22.5000, 22.5000, 22.5000, 22.5000, 22.5000, 22.5000, 22.5000, 26.2500,\n",
      "        26.2500, 26.2500, 26.2500, 26.2500, 26.2500, 26.2500, 26.2500, 26.2500,\n",
      "        26.2500, 26.2500, 26.2500,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  5.6250,  5.6250,\n",
      "         5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,\n",
      "         5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,\n",
      "         5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,\n",
      "         5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,\n",
      "         5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,\n",
      "         5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250,\n",
      "         5.6250,  5.6250,  5.6250,  5.6250,  5.6250,  5.6250, 10.1613, 10.1613,\n",
      "        10.1613, 10.1613, 10.1613, 10.1613, 10.1613, 10.1613,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583, 26.2500, 26.2500, 26.2500, 26.2500,\n",
      "        26.2500, 26.2500, 26.2500, 26.2500, 26.2500, 26.2500, 26.2500, 26.2500,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583,\n",
      "         3.0583,  3.0583,  3.0583,  3.0583,  3.0583,  3.0583, 24.2308, 24.2308,\n",
      "        24.2308, 24.2308, 24.2308, 24.2308, 24.2308, 24.2308, 24.2308, 24.2308,\n",
      "        24.2308, 24.2308, 24.2308, 15.7500, 15.7500, 15.7500, 15.7500, 15.7500,\n",
      "        15.7500, 15.7500, 15.7500, 15.7500, 15.7500, 15.7500, 15.7500, 15.7500,\n",
      "        15.7500, 15.7500, 15.7500, 15.7500, 15.7500, 15.7500, 15.7500, 26.2500,\n",
      "        26.2500, 26.2500, 26.2500, 26.2500, 26.2500, 26.2500, 26.2500, 26.2500,\n",
      "        26.2500, 26.2500, 26.2500], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "test_weighted_sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "loss_names = ['FocalSymmetricLovaszHardLogLoss']\n",
    "split_names = ['random_ext_folds5', \n",
    "               'random_ext_noleak_clean_folds5']\n",
    "\n",
    "\n",
    "def main_training(dir_data, dir_mdata, dir_results, out_dir, gpu_id='0', \n",
    "                  arch='class_densenet121_dropout', model_multicell=None, \n",
    "                  num_classes=19, in_channels=4, loss='FocalSymmetricLovaszHardLogLoss',\n",
    "                  scheduler='Adam45', epochs=55, img_size=768, crop_size=512, batch_size=32, \n",
    "                  workers=3, pin_memory=True, split_name='random_ext_folds5', fold=0, \n",
    "                  clipnorm=1, resume=None):\n",
    "    '''\n",
    "    PyTorch Protein Classification.  Main training function.\n",
    "    \n",
    "    Args:\n",
    "        dir_data (str, Path): Directory where training subsets are.\n",
    "        dir_mdata (str, Path): Directory where training meta data is.\n",
    "        dir_results (std, Path): Directory to save training results.\n",
    "        out_dir (str): \n",
    "            Name/label for this training run.  Will be used to create\n",
    "            directory under `dir_results`.\n",
    "        gpu_id (str): GPU id used for training. Default: '0'\n",
    "        arch (str): Model architecture.  \n",
    "            Default: ``'class_densenet121_dropout'``\n",
    "        model_multicell (Path, str): Path to multi-cell model \n",
    "            to start training from. Default: None\n",
    "        num_classes (int): Number of classes. Default: 19 \n",
    "        in_channels (int): In channels. Default: 4\n",
    "        loss (str, optional): Loss function. \n",
    "            One of ``'FocalSymmetricLovaszHardLogLoss'``. \n",
    "            Default: ``'FocalSymmetricLovaszHardLogLoss'``\n",
    "        scheduler (str): Scheduler name. Default: ``'Adam45'``\n",
    "        epochs (int): Number of total epochs to run. Default: 55\n",
    "        img_size (int): Image size.  Default: 768\n",
    "        crop_size (int): Crop size.  Default: 512\n",
    "        batch_size (int): Train mini-batch size. Default: 32\n",
    "        workers (int): Number of data loading workers. Default: 3\n",
    "        pin_memory (bool): DataLoader's ``pin_memory`` argument.\n",
    "        split_name (str, optional): Split name.  \n",
    "            One of: ``'random_ext_folds5'``, \n",
    "            or ``'random_ext_noleak_clean_folds5'``. \n",
    "            Default: ``'random_ext_folds5'``\n",
    "        fold (int): Index of fold. Default: 0\n",
    "        clipnorm (int): Clip grad norm'. Default: 1\n",
    "        resume (str): Name of the latest checkpoint. Default: None\n",
    "    '''\n",
    "    log_out_dir = opj(dir_results, 'logs', out_dir, 'fold%d' % fold)\n",
    "    if not ope(log_out_dir):\n",
    "        os.makedirs(log_out_dir)\n",
    "    log = Logger()\n",
    "    log.open(opj(log_out_dir, 'log.train.txt'), mode='a')\n",
    "\n",
    "    model_out_dir = opj(dir_results, 'models', out_dir, 'fold%d' % fold)\n",
    "    log.write(\">> Creating directory if it does not exist:\\n>> '{}'\\n\".format(model_out_dir))\n",
    "    if not ope(model_out_dir):\n",
    "        os.makedirs(model_out_dir)\n",
    "\n",
    "    # set cuda visible device\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # set random seeds\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    model_params = {}\n",
    "    model_params['architecture'] = arch\n",
    "    model_params['num_classes'] = num_classes\n",
    "    model_params['in_channels'] = in_channels\n",
    "    model = init_network(model_params, model_multicell=model_multicell)\n",
    "    \n",
    "    if model_multicell is not None:\n",
    "        torch.load(model_multicell)\n",
    "\n",
    "    # move network to gpu\n",
    "    model = DataParallel(model)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # define loss function (criterion)\n",
    "    try:\n",
    "        criterion = eval(loss)().to(DEVICE)\n",
    "    except:\n",
    "        raise(RuntimeError(\"Loss {} not available!\".format(loss)))\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_loss = 1e5\n",
    "    best_epoch = 0\n",
    "    best_focal = 1e5\n",
    "\n",
    "    # define scheduler\n",
    "    try:\n",
    "        scheduler = eval(scheduler)()\n",
    "    except:\n",
    "        raise (RuntimeError(\"Scheduler {} not available!\".format(scheduler)))\n",
    "    optimizer = scheduler.schedule(model, start_epoch, epochs)[0]\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if resume:\n",
    "        resume = os.path.join(model_out_dir, resume)\n",
    "        if os.path.isfile(resume):\n",
    "            # load checkpoint weights and update model and optimizer\n",
    "            log.write(\">> Loading checkpoint:\\n>> '{}'\\n\".format(resume))\n",
    "\n",
    "            checkpoint = torch.load(resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_epoch = checkpoint['best_epoch']\n",
    "            best_focal = checkpoint['best_score']\n",
    "            model.module.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "            optimizer_fpath = resume.replace('.pth', '_optim.pth')\n",
    "            if ope(optimizer_fpath):\n",
    "                log.write(\">> Loading checkpoint:\\n>> '{}'\\n\".format(optimizer_fpath))\n",
    "                optimizer.load_state_dict(torch.load(optimizer_fpath)['optimizer'])\n",
    "            log.write(\">>>> loaded checkpoint:\\n>>>> '{}' (epoch {})\\n\".format(resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            log.write(\">> No checkpoint found at '{}'\\n\".format(resume))\n",
    "\n",
    "    # Data loading code\n",
    "    train_transform = train_multi_augment2\n",
    "    train_split_file = dir_mdata / 'split'/ split_name / f'random_train_cv{fold}.feather'\n",
    "    train_dataset = ProteinDataset(\n",
    "        dir_data,\n",
    "        train_split_file,\n",
    "        img_size=img_size,\n",
    "        is_trainset=True,\n",
    "        return_label=True,\n",
    "        in_channels=in_channels,\n",
    "        transform=train_transform,\n",
    "        crop_size=crop_size,\n",
    "        random_crop=True)\n",
    "    \n",
    "    label_weights = get_label_weights(train_dataset.split_df)\n",
    "    weights = torch.from_numpy(train_dataset.split_df['Target']\n",
    "                               .apply(lambda o: label_weights[o]).values)\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=sampler,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "        num_workers=workers,\n",
    "        pin_memory=pin_memory)\n",
    "    \n",
    "    valid_split_file = (dir_mdata/'split'/split_name/\n",
    "                        f'random_valid_cv{fold}.feather')\n",
    "    \n",
    "    valid_dataset = ProteinDataset(\n",
    "        dir_data,\n",
    "        valid_split_file,\n",
    "        img_size=img_size,\n",
    "        is_trainset=True,\n",
    "        return_label=True,\n",
    "        in_channels=in_channels,\n",
    "        transform=None,\n",
    "        crop_size=crop_size,\n",
    "        random_crop=False)\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        sampler=SequentialSampler(valid_dataset),\n",
    "        batch_size=batch_size,\n",
    "        drop_last=False,\n",
    "        num_workers=workers,\n",
    "        pin_memory=pin_memory)\n",
    "\n",
    "    focal_loss = FocalLoss().to(DEVICE)\n",
    "    log.write('** start training here! **\\n')\n",
    "    log.write('\\n')\n",
    "    log.write('epoch    iter      rate     |  train_loss/acc  |    valid_loss/acc/focal/kaggle     |best_epoch/best_focal|  min \\n')\n",
    "    log.write('-----------------------------------------------------------------------------------------------------------------\\n')\n",
    "    start_epoch += 1\n",
    "    for epoch in range(start_epoch, epochs + 1):\n",
    "        end = time.time()\n",
    "\n",
    "        # set manual seeds per epoch\n",
    "        np.random.seed(epoch)\n",
    "        torch.manual_seed(epoch)\n",
    "        torch.cuda.manual_seed_all(epoch)\n",
    "\n",
    "        # adjust learning rate for each epoch\n",
    "        lr_list = scheduler.step(model, epoch, epochs)\n",
    "        lr = lr_list[0]\n",
    "\n",
    "        # train for one epoch on train set\n",
    "        iter, train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch, clipnorm=clipnorm, lr=lr)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valid_loss, valid_acc, valid_focal_loss, kaggle_score = validate(valid_loader, model, criterion, epoch, focal_loss)\n",
    "\n",
    "        # remember best loss and save checkpoint\n",
    "        is_best = valid_focal_loss < best_focal\n",
    "        best_loss = min(valid_focal_loss, best_loss)\n",
    "        best_epoch = epoch if is_best else best_epoch\n",
    "        best_focal = valid_focal_loss if is_best else best_focal\n",
    "\n",
    "        print('\\r', end='', flush=True)\n",
    "        log.write('%5.1f   %5d    %0.6f   |  %0.4f  %0.4f  |    %0.4f  %6.4f %6.4f %6.4f    |  %6.1f    %6.4f   | %3.1f min \\n' % \\\n",
    "                  (epoch, iter + 1, lr, train_loss, train_acc, valid_loss, valid_acc, valid_focal_loss, kaggle_score,\n",
    "                   best_epoch, best_focal, (time.time() - end) / 60))\n",
    "\n",
    "        save_model(model, is_best, model_out_dir, optimizer=optimizer, epoch=epoch, best_epoch=best_epoch, best_focal=best_focal)\n",
    "\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, clipnorm=1, lr=1e-5):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    num_its = len(train_loader)\n",
    "    end = time.time()\n",
    "    iter = 0\n",
    "    print_freq = 1\n",
    "    for iter, iter_data in enumerate(train_loader, 0):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # zero out gradients so we can accumulate new ones over batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images, labels, indices = iter_data\n",
    "        images = Variable(images.to(DEVICE))\n",
    "        labels = Variable(labels.to(DEVICE))\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels, epoch=epoch)\n",
    "\n",
    "        losses.update(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), clipnorm)\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        logits = outputs\n",
    "        probs = F.sigmoid(logits)\n",
    "        acc = multi_class_acc(probs, labels)\n",
    "        accuracy.update(acc.item())\n",
    "\n",
    "        if (iter + 1) % print_freq == 0 or iter == 0 or (iter + 1) == num_its:\n",
    "            print('\\r%5.1f   %5d    %0.6f   |  %0.4f  %0.4f  | ... ' % \\\n",
    "                  (epoch - 1 + (iter + 1) / num_its, iter + 1, lr, losses.avg, accuracy.avg), \\\n",
    "                  end='', flush=True)\n",
    "\n",
    "    return iter, losses.avg, accuracy.avg\n",
    "\n",
    "def validate(valid_loader, model, criterion, epoch, focal_loss, threshold=0.5):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    probs_list = []\n",
    "    labels_list = []\n",
    "    logits_list = []\n",
    "\n",
    "    end = time.time()\n",
    "    for it, iter_data in enumerate(valid_loader, 0):\n",
    "        images, labels, indices = iter_data\n",
    "        images = Variable(images.to(DEVICE))\n",
    "        labels = Variable(labels.to(DEVICE))\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels, epoch=epoch)\n",
    "\n",
    "        logits = outputs\n",
    "        probs = F.sigmoid(logits)\n",
    "        acc = multi_class_acc(probs, labels)\n",
    "\n",
    "        probs_list.append(probs.cpu().detach().numpy())\n",
    "        labels_list.append(labels.cpu().detach().numpy())\n",
    "        logits_list.append(logits.cpu().detach().numpy())\n",
    "\n",
    "        losses.update(loss.item())\n",
    "        accuracy.update(acc.item())\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    probs = np.vstack(probs_list)\n",
    "    y_true = np.vstack(labels_list)\n",
    "    logits = np.vstack(logits_list)\n",
    "    valid_focal_loss = focal_loss.forward(torch.from_numpy(logits), torch.from_numpy(y_true))\n",
    "\n",
    "    y_pred = probs > threshold\n",
    "    kaggle_score = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    return losses.avg, accuracy.avg, valid_focal_loss, kaggle_score\n",
    "\n",
    "def save_model(model, is_best, model_out_dir, optimizer=None, epoch=None, best_epoch=None, best_focal=None):\n",
    "    if type(model) == DataParallel:\n",
    "        state_dict = model.module.state_dict()\n",
    "    else:\n",
    "        state_dict = model.state_dict()\n",
    "    for key in state_dict.keys():\n",
    "        state_dict[key] = state_dict[key].cpu()\n",
    "\n",
    "    model_fpath = opj(model_out_dir, '%03d.pth' % epoch)\n",
    "    torch.save({\n",
    "        'save_dir': model_out_dir,\n",
    "        'state_dict': state_dict,\n",
    "        'best_epoch': best_epoch,\n",
    "        'epoch': epoch,\n",
    "        'best_score': best_focal,\n",
    "    }, model_fpath)\n",
    "\n",
    "    optim_fpath = opj(model_out_dir, '%03d_optim.pth' % epoch)\n",
    "    if optimizer is not None:\n",
    "        torch.save({\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, optim_fpath)\n",
    "\n",
    "    if is_best:\n",
    "        best_model_fpath = opj(model_out_dir, 'final.pth')\n",
    "        shutil.copyfile(model_fpath, best_model_fpath)\n",
    "        if optimizer is not None:\n",
    "            best_optim_fpath = opj(model_out_dir, 'final_optim.pth')\n",
    "            shutil.copyfile(optim_fpath, best_optim_fpath)\n",
    "\n",
    "def multi_class_acc(preds, targs, th=0.5):\n",
    "    preds = (preds > th).int()\n",
    "    targs = targs.int()\n",
    "    return (preds == targs).float().mean()\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0.\n",
    "        self.avg = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_results = Path('results')\n",
    "dir_results.mkdir(exist_ok=True, parents=True)\n",
    "out_dir = Path('external_crop256_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds')\n",
    "model_multicell = (\n",
    "    '../../kgl_humanprotein_data/result/models/'\n",
    "    'external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds/'\n",
    "    'fold0/final.pth')\n",
    "gpu_id = '0' # '0,1,2,3'\n",
    "arch = 'class_densenet121_dropout'\n",
    "num_classes = len(LABEL_NAME_LIST)\n",
    "scheduler = 'Adam55'\n",
    "epochs = 2 #55\n",
    "resume = '001.pth'\n",
    "sz_img = 384\n",
    "crop_size = 64 #512\n",
    "batch_size = 32\n",
    "split_name = 'random_folds5'\n",
    "fold = 0\n",
    "workers = 0 # 3\n",
    "pin_memory = False  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating directory if it does not exist:\n",
      ">> 'results/models/external_crop256_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds/fold0'\n",
      ">> Using pre-trained model.\n",
      ">> Loading multi-cell model.\n",
      ">> Loading checkpoint:\n",
      ">> 'results/models/external_crop256_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds/fold0/001.pth'\n",
      ">> Loading checkpoint:\n",
      ">> 'results/models/external_crop256_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds/fold0/001_optim.pth'\n",
      ">>>> loaded checkpoint:\n",
      ">>>> 'results/models/external_crop256_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds/fold0/001.pth' (epoch 1)\n",
      "** start training here! **\n",
      "\n",
      "epoch    iter      rate     |  train_loss/acc  |    valid_loss/acc/focal/kaggle     |best_epoch/best_focal|  min \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "  2.0       9    0.000300   |  38.5619  0.5519  |    14.4570  0.6470 22.1923 0.1003    |     2.0    22.1923   | 0.4 min \n"
     ]
    }
   ],
   "source": [
    "main_training(dir_data, dir_mdata, dir_results, out_dir, \n",
    "              split_name=split_name, fold=fold,\n",
    "              arch=arch, model_multicell=model_multicell, scheduler=scheduler,\n",
    "              epochs=epochs, resume=resume,\n",
    "              img_size=sz_img, crop_size=crop_size, batch_size=batch_size, \n",
    "              gpu_id=gpu_id, workers=workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362M\tresults/models/external_crop256_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds/fold0/\r\n"
     ]
    }
   ],
   "source": [
    "! du -hs results/models/external_crop256_focal_slov_hardlog_class_densenet121_dropout_i384_aug2_5folds/fold0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
