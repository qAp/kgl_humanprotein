{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `layers.scheduler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp layers.scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.optim as optim\n",
    "from kgl_humanprotein.layers.scheduler_base import SchedulerBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Adam45(SchedulerBase):\n",
    "    def __init__(self, params_list=None):\n",
    "        super(Adam45, self).__init__()\n",
    "        self._lr = 3e-4\n",
    "        self._cur_optimizer = None\n",
    "        self.params_list=params_list\n",
    "\n",
    "    def schedule(self, net, epoch, epochs, **kwargs):\n",
    "        lr = 30e-5\n",
    "        if epoch > 25:\n",
    "            lr = 15e-5\n",
    "        if epoch > 30:\n",
    "            lr = 7.5e-5\n",
    "        if epoch > 35:\n",
    "            lr = 3e-5\n",
    "        if epoch > 40:\n",
    "            lr = 1e-5\n",
    "        self._lr = lr\n",
    "        if self._cur_optimizer is None:\n",
    "            self._cur_optimizer = optim.Adam(net.parameters(), lr=lr)#, weight_decay=0.0005\n",
    "        return self._cur_optimizer, self._lr\n",
    "\n",
    "\n",
    "class Adam55(SchedulerBase):\n",
    "    def __init__(self, params_list=None):\n",
    "        super(Adam55, self).__init__()\n",
    "        self._lr = 3e-4\n",
    "        self._cur_optimizer = None\n",
    "        self.params_list=params_list\n",
    "\n",
    "    def schedule(self,net, epoch, epochs, **kwargs):\n",
    "        lr = 30e-5\n",
    "        if epoch > 25:\n",
    "            lr = 15e-5\n",
    "        if epoch > 35:\n",
    "            lr = 7.5e-5\n",
    "        if epoch > 45:\n",
    "            lr = 3e-5\n",
    "        if epoch > 50:\n",
    "            lr = 1e-5\n",
    "        self._lr = lr\n",
    "        if self._cur_optimizer is None:\n",
    "            self._cur_optimizer = optim.Adam(net.parameters(), lr=lr)#, weight_decay=0.0005\n",
    "        return self._cur_optimizer, self._lr\n",
    "\n",
    "class FaceAdam(SchedulerBase):\n",
    "    def __init__(self,params_list=None):\n",
    "        super(FaceAdam, self).__init__()\n",
    "        self._lr = 2e-4\n",
    "        self._cur_optimizer = None\n",
    "        self.params_list=params_list\n",
    "\n",
    "    def schedule(self, net, epoch, epochs, **kwargs):\n",
    "        lr = 1e-4\n",
    "        self._lr = lr\n",
    "        if self._cur_optimizer is None:\n",
    "            self._cur_optimizer = optim.Adam(net.parameters(), lr=lr)  # , weight_decay=0.0005\n",
    "        return self._cur_optimizer, self._lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
