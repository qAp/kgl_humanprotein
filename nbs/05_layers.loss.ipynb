{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `layers.loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../HPA-competition-solutions/bestfitting/src/layers/loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp layers.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on collie.local\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from kgl_humanprotein.config.config import *\n",
    "from kgl_humanprotein.layers.hard_example import *\n",
    "from kgl_humanprotein.layers.lovasz_losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logit, target, epoch=0):\n",
    "        target = target.float()\n",
    "        max_val = (-logit).clamp(min=0)\n",
    "        loss = logit - logit * target + max_val + \\\n",
    "               ((-max_val).exp() + (-logit - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-logit * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        if len(loss.size())==2:\n",
    "            loss = loss.sum(dim=1)\n",
    "        return loss.mean()\n",
    "\n",
    "class HardLogLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HardLogLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.__classes_num = NUM_CLASSES\n",
    "\n",
    "    def forward(self, logits, labels,epoch=0):\n",
    "        labels = labels.float()\n",
    "        loss=0\n",
    "        for i in range(NUM_CLASSES):\n",
    "            logit_ac=logits[:,i]\n",
    "            label_ac=labels[:,i]\n",
    "            logit_ac, label_ac=get_hard_samples(logit_ac,label_ac)\n",
    "            loss+=self.bce_loss(logit_ac,label_ac)\n",
    "        loss = loss/NUM_CLASSES\n",
    "        return loss\n",
    "\n",
    "# https://github.com/bermanmaxim/LovaszSoftmax/tree/master/pytorch\n",
    "def lovasz_hinge(logits, labels, ignore=None, per_class=True):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, C] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, C] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_class:\n",
    "        loss = 0\n",
    "        for i in range(NUM_CLASSES):\n",
    "            logit_ac = logits[:, i]\n",
    "            label_ac = labels[:, i]\n",
    "            loss += lovasz_hinge_flat(logit_ac, label_ac)\n",
    "        loss = loss / NUM_CLASSES\n",
    "    else:\n",
    "        logits = logits.view(-1)\n",
    "        labels = labels.view(-1)\n",
    "        loss = lovasz_hinge_flat(logits, labels)\n",
    "    return loss\n",
    "\n",
    "# https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/69053\n",
    "class SymmetricLovaszLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SymmetricLovaszLoss, self).__init__()\n",
    "        self.__classes_num = NUM_CLASSES\n",
    "\n",
    "    def forward(self, logits, labels,epoch=0):\n",
    "        labels = labels.float()\n",
    "        loss=((lovasz_hinge(logits, labels)) + (lovasz_hinge(-logits, 1 - labels))) / 2\n",
    "        return loss\n",
    "\n",
    "class FocalSymmetricLovaszHardLogLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FocalSymmetricLovaszHardLogLoss, self).__init__()\n",
    "        self.focal_loss = FocalLoss()\n",
    "        self.slov_loss = SymmetricLovaszLoss()\n",
    "        self.log_loss = HardLogLoss()\n",
    "    def forward(self, logit, labels,epoch=0):\n",
    "        labels = labels.float()\n",
    "        focal_loss = self.focal_loss.forward(logit, labels, epoch)\n",
    "        slov_loss = self.slov_loss.forward(logit, labels, epoch)\n",
    "        log_loss = self.log_loss.forward(logit, labels, epoch)\n",
    "        loss = focal_loss*0.5 + slov_loss*0.5 +log_loss * 0.5\n",
    "        return loss\n",
    "\n",
    "# https://github.com/ronghuaiyang/arcface-pytorch\n",
    "class ArcFaceLoss(nn.modules.Module):\n",
    "    def __init__(self,s=30.0,m=0.5):\n",
    "        super(ArcFaceLoss, self).__init__()\n",
    "        self.classify_loss = nn.CrossEntropyLoss()\n",
    "        self.s = s\n",
    "        self.easy_margin = False\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, logits, labels, epoch=0):\n",
    "        cosine = logits\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, labels.view(-1, 1).long(), 1)\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        loss1 = self.classify_loss(output, labels)\n",
    "        loss2 = self.classify_loss(cosine, labels)\n",
    "        gamma=1\n",
    "        loss=(loss1+gamma*loss2)/(1+gamma)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
