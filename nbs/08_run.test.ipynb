{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp run.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../../HPA-competition-solutions/bestfitting/src/run/test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on collie.local\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch.nn import DataParallel\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from kgl_humanprotein.config.config import *\n",
    "from kgl_humanprotein.utils.common_util import *\n",
    "from kgl_humanprotein.networks.imageclsnet import init_network\n",
    "from kgl_humanprotein.datasets.protein_dataset import ProteinDataset\n",
    "from kgl_humanprotein.utils.augment_util import *\n",
    "from kgl_humanprotein.utils.log_util import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "datasets_names = ['test', 'val']\n",
    "split_names = ['random_ext_folds5', 'random_ext_noleak_clean_folds5']\n",
    "augment_list = ['default', 'flipud', 'fliplr','transpose', 'flipud_lr',\n",
    "                'flipud_transpose', 'fliplr_transpose', 'flipud_lr_transpose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on collie.local\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "def test(outdir, gpu_id='0', arch='class_densenet121_dropout', \n",
    "         num_classes=28, in_channels=4, img_size=768, crop_size=512, \n",
    "         batch_size=32, workers=3, fold=0, augment='default', seed=100,  \n",
    "         seeds=None, dataset='test', split_name='random_ext_folds5',\n",
    "         predict_epoch=None):  \n",
    "    '''\n",
    "    PyTorch Protein Classification\n",
    "    \n",
    "    Args:\n",
    "        outdir (str): Destination where predicted result should be saved.\n",
    "        gpu_id (str): GPU id used for predicting. Default: ``'0'``\n",
    "        arch (str): Model architecture. Default: ``'class_densenet121_dropout)'``\n",
    "        num_classes (int): Number of classes. Default: 28\n",
    "        in_channels (int): In channels. Default: 4\n",
    "        img_size (int):  Image size. Default: 768\n",
    "        crop_size (int): Crop size. Default: 512\n",
    "        batch_size (int): Train mini-batch size. Default: 32\n",
    "        workers (int): Number of data loading workers. Default: 3\n",
    "        fold (int): Index of fold. Default: 0\n",
    "        augment (str):  Comma-separated string of one or more of \n",
    "            the following: ``'default'``, ``'flipud'``, ``'fliplr'``,\n",
    "            ``'transpose'``, ``'flipud_lr'``, ``'flipud_transpose'``, \n",
    "            ``'fliplr_transpose'``, ``'flipud_lr_transpose'``.\n",
    "            Default: ``'default'``\n",
    "        seed (int):  Random seed. Default: 100\n",
    "        seeds (str): Predict seed. Default: None\n",
    "        dataset (str, optional): ``'test'``, or ``'val'``. Default: ``'test'``\n",
    "        split_name (str, optional): ``'random_ext_folds5'``, or\n",
    "            ``'random_ext_noleak_clean_folds5'``. Default: 'random_ext_folds5'\n",
    "        predict_epoch (int): Number epoch to predict. Default: None\n",
    "    '''\n",
    "    if dataset not in datasets_names:\n",
    "        print(f'`dataset` needs to be one of {datasets_names}.')\n",
    "        raise\n",
    "\n",
    "    if split_name not in split_names:\n",
    "        print(f'`split_name` must be one of {split_names}.')\n",
    "        raise\n",
    "\n",
    "    log_out_dir = opj(RESULT_DIR, 'logs', out_dir, 'fold%d' % fold)\n",
    "    if not ope(log_out_dir):\n",
    "        os.makedirs(log_out_dir)\n",
    "    log = Logger()\n",
    "    log.open(opj(log_out_dir, 'log.submit.txt'), mode='a')\n",
    "\n",
    "    predict_epoch = 'final' if predict_epoch is None else '%03d' % predict_epoch\n",
    "    network_path = opj(RESULT_DIR, 'models', out_dir, 'fold%d' % fold, '%s.pth' % predict_epoch)\n",
    "\n",
    "    submit_out_dir = opj(RESULT_DIR, 'submissions', out_dir, 'fold%d' % fold, 'epoch_%s' % predict_epoch)\n",
    "    log.write(\">> Creating directory if it does not exist:\\n>> '{}'\\n\".format(submit_out_dir))\n",
    "    if not ope(submit_out_dir):\n",
    "        os.makedirs(submit_out_dir)\n",
    "\n",
    "    # setting up the visible GPU\n",
    "    if torch.cuda.is_available():\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    augment = augment.split(',')\n",
    "    for augment_ in augment:\n",
    "        if augment_ not in augment_list:\n",
    "            raise ValueError('Unsupported or unknown test augmentation: {}!'.format(augment))\n",
    "\n",
    "    model_params = {}\n",
    "    model_params['architecture'] = arch\n",
    "    model_params['num_classes'] = num_classes\n",
    "    model_params['in_channels'] = in_channels\n",
    "    model = init_network(model_params)\n",
    "\n",
    "    log.write(\">> Loading network:\\n>>>> '{}'\\n\".format(network_path))\n",
    "    checkpoint = torch.load(network_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    log.write(\">>>> loaded network:\\n>>>> epoch {}\\n\".format(checkpoint['epoch']))\n",
    "\n",
    "    # moving network to gpu and eval mode\n",
    "    model = DataParallel(model)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Data loading code\n",
    "    if dataset == 'test':\n",
    "        test_split_file = opj(DATA_DIR, 'split', 'train.csv')\n",
    "    elif dataset == 'val':\n",
    "        test_split_file = opj(DATA_DIR, 'split', split_name, 'random_valid_cv%d.csv' % fold)\n",
    "    else:\n",
    "        raise ValueError('Unsupported or unknown dataset: {}!'.format(dataset))\n",
    "    test_dataset = ProteinDataset(\n",
    "        test_split_file,\n",
    "        img_size=img_size,\n",
    "        is_trainset=(dataset != 'test'),\n",
    "        return_label=False,\n",
    "        in_channels=in_channels,\n",
    "        transform=None,\n",
    "        crop_size=crop_size,\n",
    "        random_crop=False,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        sampler=SequentialSampler(test_dataset),\n",
    "        batch_size=batch_size,\n",
    "        drop_last=False,\n",
    "        num_workers=workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return test_dataset\n",
    "\n",
    "#     seeds = [seed] if seeds is None else [int(i) for i in seeds.split(',')]\n",
    "#     for seed in seeds:\n",
    "#         test_dataset.random_crop = (seed != 0)\n",
    "#         for augment_ in augment:\n",
    "#             test_loader.dataset.transform = eval('augment_%s' % augment_)\n",
    "#             if crop_size > 0:\n",
    "#                 sub_submit_out_dir = opj(submit_out_dir, '%s_seed%d' % (augment_, seed))\n",
    "#             else:\n",
    "#                 sub_submit_out_dir = opj(submit_out_dir, augment_)\n",
    "#             if not ope(sub_submit_out_dir):\n",
    "#                 os.makedirs(sub_submit_out_dir)\n",
    "#             with torch.no_grad():\n",
    "#                 predict(test_loader, model, sub_submit_out_dir, dataset)\n",
    "\n",
    "def predict(test_loader, model, submit_out_dir, dataset):\n",
    "    all_probs = []\n",
    "    img_ids = np.array(test_loader.dataset.img_ids)\n",
    "    for it, iter_data in tqdm(enumerate(test_loader, 0), total=len(test_loader)):\n",
    "        images, indices = iter_data\n",
    "        images = Variable(images.to(device), volatile=True)\n",
    "        outputs = model(images)\n",
    "        logits = outputs\n",
    "\n",
    "        probs = F.sigmoid(logits).data\n",
    "        all_probs += probs.cpu().numpy().tolist()\n",
    "    img_ids = img_ids[:len(all_probs)]\n",
    "    all_probs = np.array(all_probs).reshape(len(img_ids), -1)\n",
    "\n",
    "    np.save(opj(submit_out_dir, 'prob_%s.npy' % dataset), all_probs)\n",
    "\n",
    "    result_df = prob_to_result(all_probs, img_ids)\n",
    "    result_df.to_csv(opj(submit_out_dir, 'results_%s.csv.gz' % dataset), index=False, compression='gzip')\n",
    "\n",
    "def prob_to_result(probs, img_ids, th=0.5):\n",
    "    probs = probs.copy()\n",
    "    probs[np.arange(len(probs)), np.argmax(probs, axis=1)] = 1\n",
    "\n",
    "    pred_list = []\n",
    "    for line in probs:\n",
    "        s = ' '.join(list([str(i) for i in np.nonzero(line > th)[0]]))\n",
    "        pred_list.append(s)\n",
    "    result_df = pd.DataFrame({ID: img_ids, PREDICTED: pred_list})\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python test.py \\\n",
    "#             --out_dir external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds \\\n",
    "#             --gpu_id 0 --arch class_densenet121_dropout \\\n",
    "#             --img_size 768 --crop_size 512 --seeds 0,1,2,3 --batch_size 12 --fold 0 \\\n",
    "#             --augment\n",
    "\n",
    "out_dir = 'external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds'\n",
    "\n",
    "kwargs = dict(\n",
    "    gpu_id = '0',\n",
    "    arch = 'class_densenet121_dropout',\n",
    "    img_size = 768,\n",
    "    crop_size = 512,\n",
    "    seeds = '0,1,2,3',\n",
    "    batch_size = 12,\n",
    "    fold = 0,\n",
    "    augment = 'default,flipud,fliplr,transpose,flipud_lr,flipud_transpose,fliplr_transpose,flipud_lr_transpose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on collie.local\n",
      ">> Creating directory if it does not exist:\n",
      ">> '../data/result/submissions/external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds/fold0/epoch_final'\n",
      ">> Using pre-trained model.\n",
      ">> Loading network:\n",
      ">>>> '../data/result/models/external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds/fold0/final.pth'\n",
      ">>>> loaded network:\n",
      ">>>> epoch 52\n",
      "../data/protein/test/images_768\n",
      "../data/protein/train/external_v18_768\n"
     ]
    }
   ],
   "source": [
    "ds = test(out_dir, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_rgby\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Cannot find ../data/protein/test/images_768/000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0_5_red.png",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-056a52796414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git_repos/kgl_humanprotein/kgl_humanprotein/datasets/protein_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_rgby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_repos/kgl_humanprotein/kgl_humanprotein/datasets/protein_dataset.py\u001b[0m in \u001b[0;36mread_rgby\u001b[0;34m(self, img_dir, img_id, index)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mfns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mopj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Cannot find {fn}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         img = [cv2.imread(opj(img_dir, img_id + '_' + color + suffix), flags)\n\u001b[1;32m     95\u001b[0m                for color in colors]\n",
      "\u001b[0;31mAssertionError\u001b[0m: Cannot find ../data/protein/test/images_768/000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0_5_red.png"
     ]
    }
   ],
   "source": [
    "ds[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
